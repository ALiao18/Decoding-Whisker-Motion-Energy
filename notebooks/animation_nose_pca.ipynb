{"cells":[{"cell_type":"markdown","metadata":{"id":"lvBc4yFubJyQ"},"source":["# Setup"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":39503,"status":"ok","timestamp":1753731244374,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"G0QQWkAlTKKU","outputId":"7efd4295-1e66-4e97-de93-708eb5e7fd85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: ONE-api in /usr/local/lib/python3.11/dist-packages (3.3.0)\n","Requirement already satisfied: ruff in /usr/local/lib/python3.11/dist-packages (from ONE-api) (0.12.4)\n","Requirement already satisfied: numpy\u003e=1.18 in /usr/local/lib/python3.11/dist-packages (from ONE-api) (2.0.2)\n","Requirement already satisfied: pandas\u003e=1.5.0 in /usr/local/lib/python3.11/dist-packages (from ONE-api) (2.2.2)\n","Requirement already satisfied: tqdm\u003e=4.32.1 in /usr/local/lib/python3.11/dist-packages (from ONE-api) (4.67.1)\n","Requirement already satisfied: requests\u003e=2.22.0 in /usr/local/lib/python3.11/dist-packages (from ONE-api) (2.32.3)\n","Requirement already satisfied: iblutil\u003e=1.14.0 in /usr/local/lib/python3.11/dist-packages (from ONE-api) (1.20.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ONE-api) (25.0)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from ONE-api) (1.39.14)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ONE-api) (6.0.2)\n","Requirement already satisfied: colorlog\u003e=6.0.0 in /usr/local/lib/python3.11/dist-packages (from iblutil\u003e=1.14.0-\u003eONE-api) (6.9.0)\n","Requirement already satisfied: numba\u003e0.53.1 in /usr/local/lib/python3.11/dist-packages (from iblutil\u003e=1.14.0-\u003eONE-api) (0.60.0)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from iblutil\u003e=1.14.0-\u003eONE-api) (18.1.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from iblutil\u003e=1.14.0-\u003eONE-api) (1.16.0)\n","Requirement already satisfied: python-dateutil\u003e=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.5.0-\u003eONE-api) (2.9.0.post0)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.5.0-\u003eONE-api) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas\u003e=1.5.0-\u003eONE-api) (2025.2)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eONE-api) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eONE-api) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eONE-api) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eONE-api) (2025.7.14)\n","Requirement already satisfied: botocore\u003c1.40.0,\u003e=1.39.14 in /usr/local/lib/python3.11/dist-packages (from boto3-\u003eONE-api) (1.39.14)\n","Requirement already satisfied: jmespath\u003c2.0.0,\u003e=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3-\u003eONE-api) (1.0.1)\n","Requirement already satisfied: s3transfer\u003c0.14.0,\u003e=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3-\u003eONE-api) (0.13.1)\n","Requirement already satisfied: llvmlite\u003c0.44,\u003e=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba\u003e0.53.1-\u003eiblutil\u003e=1.14.0-\u003eONE-api) (0.43.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil\u003e=2.8.2-\u003epandas\u003e=1.5.0-\u003eONE-api) (1.17.0)\n","Requirement already satisfied: ibllib in /usr/local/lib/python3.11/dist-packages (3.4.1)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.39.14)\n","Requirement already satisfied: click\u003e=7.0.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (8.2.1)\n","Requirement already satisfied: colorlog\u003e=4.0.2 in /usr/local/lib/python3.11/dist-packages (from ibllib) (6.9.0)\n","Requirement already satisfied: flake8\u003e=3.7.8 in /usr/local/lib/python3.11/dist-packages (from ibllib) (7.3.0)\n","Requirement already satisfied: globus-sdk in /usr/local/lib/python3.11/dist-packages (from ibllib) (3.61.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.21)\n","Requirement already satisfied: matplotlib\u003e=3.0.3 in /usr/local/lib/python3.11/dist-packages (from ibllib) (3.10.0)\n","Requirement already satisfied: numba\u003e=0.56 in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.60.0)\n","Requirement already satisfied: numpy\u003c=2.2,\u003e=1.18 in /usr/local/lib/python3.11/dist-packages (from ibllib) (2.0.2)\n","Requirement already satisfied: nptdms in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.10.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from ibllib) (4.12.0.88)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from ibllib) (2.2.2)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from ibllib) (18.1.0)\n","Requirement already satisfied: pynrrd\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.1.3)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from ibllib) (8.4.1)\n","Requirement already satisfied: requests\u003e=2.22.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (2.32.3)\n","Requirement already satisfied: scikit-learn\u003e=0.22.1 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.6.1)\n","Requirement already satisfied: scipy\u003e=1.7.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.16.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.25.2)\n","Requirement already satisfied: imagecodecs in /usr/local/lib/python3.11/dist-packages (from ibllib) (2025.3.30)\n","Requirement already satisfied: sparse in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.17.0)\n","Requirement already satisfied: seaborn\u003e=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.13.2)\n","Requirement already satisfied: tqdm\u003e=4.32.1 in /usr/local/lib/python3.11/dist-packages (from ibllib) (4.67.1)\n","Requirement already satisfied: iblatlas\u003e=0.5.3 in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.9.0)\n","Requirement already satisfied: ibl-neuropixel\u003e=1.6.2 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.8.1)\n","Requirement already satisfied: iblutil\u003e=1.13.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.20.0)\n","Requirement already satisfied: iblqt\u003e=0.4.2 in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.8.0)\n","Requirement already satisfied: mtscomp\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.0.2)\n","Requirement already satisfied: ONE-api\u003e=3.2.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (3.3.0)\n","Requirement already satisfied: phylib\u003e=2.6.0 in /usr/local/lib/python3.11/dist-packages (from ibllib) (2.6.1)\n","Requirement already satisfied: psychofit in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.0.0.post0)\n","Requirement already satisfied: slidingRP\u003e=1.1.1 in /usr/local/lib/python3.11/dist-packages (from ibllib) (1.1.1)\n","Requirement already satisfied: pyqt5 in /usr/local/lib/python3.11/dist-packages (from ibllib) (5.15.11)\n","Requirement already satisfied: ibl-style in /usr/local/lib/python3.11/dist-packages (from ibllib) (0.1.0)\n","Requirement already satisfied: mccabe\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.11/dist-packages (from flake8\u003e=3.7.8-\u003eibllib) (0.7.0)\n","Requirement already satisfied: pycodestyle\u003c2.15.0,\u003e=2.14.0 in /usr/local/lib/python3.11/dist-packages (from flake8\u003e=3.7.8-\u003eibllib) (2.14.0)\n","Requirement already satisfied: pyflakes\u003c3.5.0,\u003e=3.4.0 in /usr/local/lib/python3.11/dist-packages (from flake8\u003e=3.7.8-\u003eibllib) (3.4.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from ibl-neuropixel\u003e=1.6.2-\u003eibllib) (1.5.1)\n","Requirement already satisfied: qtpy\u003e=2.4.1 in /usr/local/lib/python3.11/dist-packages (from iblqt\u003e=0.4.2-\u003eibllib) (2.4.3)\n","Requirement already satisfied: pyqtgraph\u003e=0.13.7 in /usr/local/lib/python3.11/dist-packages (from iblqt\u003e=0.4.2-\u003eibllib) (0.13.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from iblutil\u003e=1.13.0-\u003eibllib) (25.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib\u003e=3.0.3-\u003eibllib) (1.3.2)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib\u003e=3.0.3-\u003eibllib) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib\u003e=3.0.3-\u003eibllib) (4.59.0)\n","Requirement already satisfied: kiwisolver\u003e=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib\u003e=3.0.3-\u003eibllib) (1.4.8)\n","Requirement already satisfied: pillow\u003e=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib\u003e=3.0.3-\u003eibllib) (11.3.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib\u003e=3.0.3-\u003eibllib) (3.2.3)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib\u003e=3.0.3-\u003eibllib) (2.9.0.post0)\n","Requirement already satisfied: llvmlite\u003c0.44,\u003e=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba\u003e=0.56-\u003eibllib) (0.43.0)\n","Requirement already satisfied: ruff in /usr/local/lib/python3.11/dist-packages (from ONE-api\u003e=3.2.0-\u003eibllib) (0.12.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ONE-api\u003e=3.2.0-\u003eibllib) (6.0.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003eibllib) (2025.2)\n","Requirement already satisfied: tzdata\u003e=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas-\u003eibllib) (2025.2)\n","Requirement already satisfied: dask in /usr/local/lib/python3.11/dist-packages (from phylib\u003e=2.6.0-\u003eibllib) (2025.5.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from phylib\u003e=2.6.0-\u003eibllib) (0.12.1)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from pynrrd\u003e=0.4.0-\u003eibllib) (4.14.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eibllib) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eibllib) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eibllib) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003e=2.22.0-\u003eibllib) (2025.7.14)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn\u003e=0.22.1-\u003eibllib) (3.6.0)\n","Requirement already satisfied: colorcet in /usr/local/lib/python3.11/dist-packages (from slidingRP\u003e=1.1.1-\u003eibllib) (3.1.0)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from slidingRP\u003e=1.1.1-\u003eibllib) (0.14.5)\n","Requirement already satisfied: botocore\u003c1.40.0,\u003e=1.39.14 in /usr/local/lib/python3.11/dist-packages (from boto3-\u003eibllib) (1.39.14)\n","Requirement already satisfied: jmespath\u003c2.0.0,\u003e=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3-\u003eibllib) (1.0.1)\n","Requirement already satisfied: s3transfer\u003c0.14.0,\u003e=0.13.0 in /usr/local/lib/python3.11/dist-packages (from boto3-\u003eibllib) (0.13.1)\n","Requirement already satisfied: pyjwt\u003c3.0.0,\u003e=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]\u003c3.0.0,\u003e=2.0.0-\u003eglobus-sdk-\u003eibllib) (2.10.1)\n","Requirement already satisfied: cryptography!=3.4.0,\u003e=3.3.1 in /usr/local/lib/python3.11/dist-packages (from globus-sdk-\u003eibllib) (43.0.3)\n","Requirement already satisfied: figrid in /usr/local/lib/python3.11/dist-packages (from ibl-style-\u003eibllib) (0.1.7)\n","Requirement already satisfied: PyQt5-sip\u003c13,\u003e=12.15 in /usr/local/lib/python3.11/dist-packages (from pyqt5-\u003eibllib) (12.17.0)\n","Requirement already satisfied: PyQt5-Qt5\u003c5.16.0,\u003e=5.15.2 in /usr/local/lib/python3.11/dist-packages (from pyqt5-\u003eibllib) (5.15.17)\n","Requirement already satisfied: iniconfig\u003e=1 in /usr/local/lib/python3.11/dist-packages (from pytest-\u003eibllib) (2.1.0)\n","Requirement already satisfied: pluggy\u003c2,\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest-\u003eibllib) (1.6.0)\n","Requirement already satisfied: pygments\u003e=2.7.2 in /usr/local/lib/python3.11/dist-packages (from pytest-\u003eibllib) (2.19.2)\n","Requirement already satisfied: networkx\u003e=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image-\u003eibllib) (3.5)\n","Requirement already satisfied: imageio!=2.35.0,\u003e=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image-\u003eibllib) (2.37.0)\n","Requirement already satisfied: tifffile\u003e=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image-\u003eibllib) (2025.6.11)\n","Requirement already satisfied: lazy-loader\u003e=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image-\u003eibllib) (0.4)\n","Requirement already satisfied: cffi\u003e=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography!=3.4.0,\u003e=3.3.1-\u003eglobus-sdk-\u003eibllib) (1.17.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.0.3-\u003eibllib) (1.17.0)\n","Requirement already satisfied: cloudpickle\u003e=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask-\u003ephylib\u003e=2.6.0-\u003eibllib) (3.1.1)\n","Requirement already satisfied: fsspec\u003e=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask-\u003ephylib\u003e=2.6.0-\u003eibllib) (2025.3.0)\n","Requirement already satisfied: partd\u003e=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask-\u003ephylib\u003e=2.6.0-\u003eibllib) (1.4.2)\n","Requirement already satisfied: importlib_metadata\u003e=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask-\u003ephylib\u003e=2.6.0-\u003eibllib) (8.7.0)\n","Requirement already satisfied: patsy\u003e=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels-\u003eslidingRP\u003e=1.1.1-\u003eibllib) (1.0.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi\u003e=1.12-\u003ecryptography!=3.4.0,\u003e=3.3.1-\u003eglobus-sdk-\u003eibllib) (2.22)\n","Requirement already satisfied: zipp\u003e=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata\u003e=4.13.0-\u003edask-\u003ephylib\u003e=2.6.0-\u003eibllib) (3.23.0)\n","Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd\u003e=1.4.0-\u003edask-\u003ephylib\u003e=2.6.0-\u003eibllib) (1.0.0)\n"]}],"source":["! pip install ONE-api\n","! pip install ibllib"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19862,"status":"ok","timestamp":1753731264243,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"MokwPeBtTOIK","outputId":"20a6bc94-c5b9-422c-bd82-4e0f36302844"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# Standard libraries\n","from pprint import pprint\n","import random\n","from typing import List, Dict, Optional, Tuple, Union\n","import warnings\n","import os\n","import requests\n","from pathlib import Path\n","import time\n","\n","\n","# Third-party libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from matplotlib.animation import FuncAnimation, FFMpegWriter\n","from IPython.display import HTML\n","from matplotlib.gridspec import GridSpec\n","import matplotlib as mpl\n","from datetime import datetime\n","from typing import Dict, List, Optional\n","import gc\n","from matplotlib.lines import Line2D\n","from scipy.ndimage import uniform_filter1d\n","from IPython.display import HTML, display\n","\n","# IBL-specific libraries\n","from iblatlas.atlas import BrainAtlas\n","from iblatlas import atlas\n","from ibllib.io import video\n","from one.api import ONE, OneAlyx\n","from brainbox.io.one import SessionLoader\n","\n","from one.api import ONE\n","from brainbox.io.one import SessionLoader\n","import ibllib.io.video as video\n","from iblutil.util import Bunch\n","\n","# Matplotlib animation limit\n","mpl.rcParams['animation.embed_limit'] = 200\n","\n","# Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","BASE_DIR = \"content/drive/My Drive/S25/Langone/Breathing\"\n","OUTPUT_DIR = os.path.join(BASE_DIR, 'Figures')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1116,"status":"ok","timestamp":1753731265365,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"sAcqTNVhT_9N","outputId":"7544f649-ddbf-4512-a8d7-d88b9824d66c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Connected to https://openalyx.internationalbrainlab.org as user \"intbrainlab\"\n"]}],"source":["ONE.setup(base_url='https://openalyx.internationalbrainlab.org', silent=True)\n","one = ONE(password='international')"]},{"cell_type":"markdown","metadata":{"id":"1nkBJ3NDzg1h"},"source":["# DataLoader"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1378,"status":"ok","timestamp":1753731266742,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"toz6pkyoAFji"},"outputs":[],"source":["class IBLDataLoader:\n","    def __init__(self, eid: str, verbose: bool = True, nosePCAPath: Optional[str] = None):\n","        \"\"\"\n","        Initialize the data loader for a specific experiment.\n","\n","        Args:\n","            eid (str): Experiment ID to load\n","            verbose (bool): Enable detailed logging\n","            nosePCAPath (str, optional): Full path to nose PC CSV for injection\n","        \"\"\"\n","        self.eid = eid\n","        self.verbose = verbose\n","        self.one = ONE()\n","        self.sessLoader = None\n","        self.sessionInfo = {}\n","        self.trialData = None\n","        self.poseData = None\n","        self.wheelData = None\n","        self.motionEnergyData = None\n","        self.pupilData = None\n","        self.fps = None # dictionary left, right, body\n","        self.videoTimes = None # Default aligns time to left camera, can be changed in loadVideoTimestamps() self.videoTimes = timestamps['left']\n","        self.urls = None\n","        self.nosePCAPath = nosePCAPath\n","\n","        # Features we want to track from pose data\n","        self.requiredPoseFeatures = [\n","            'times', 'nose_tip_x', 'nose_tip_y', 'pupil_top_r_x', 'pupil_top_r_y',\n","            'pupil_right_r_x', 'pupil_right_r_y', 'pupil_bottom_r_x', 'pupil_bottom_r_y',\n","            'pupil_left_r_x', 'pupil_left_r_y', 'tube_top_x', 'tube_top_y',\n","            'tube_bottom_x', 'tube_bottom_y', 'tongue_end_l_x', 'tongue_end_l_y',\n","            'tongue_end_r_x', 'tongue_end_r_y'\n","        ]\n","\n","        # Trial event features we want to extract\n","        self.requiredTrialFeatures = [\n","            'intervals_0', 'intervals_1', 'stimOff_times', 'goCueTrigger_times',\n","            'stimOn_times', 'response_times', 'goCue_times', 'firstMovement_times',\n","            'feedback_times'\n","        ]\n","\n","        if self.verbose:\n","            print(f\"Initializing IBL DataLoader for experiment: {eid}\")\n","\n","    def loadSessionData(self) -\u003e bool:\n","        \"\"\"\n","        Load all required session data using SessionLoader.\n","\n","        Returns:\n","            bool: True if loading successful, False otherwise\n","        \"\"\"\n","        try:\n","            if self.verbose:\n","                print(\"Loading session data...\")\n","\n","            # Initialize SessionLoader\n","            self.sessLoader = SessionLoader(one=self.one, eid=self.eid)\n","\n","            # Load all required data types\n","            self.sessLoader.load_session_data(\n","                trials=True,           # Task timing events\n","                wheel=True,            # Wheel movement data\n","                pose=True,             # Pose tracking (all cameras)\n","                motion_energy=True,    # Motion energy (all cameras)\n","                pupil=True,            # Pupil diameter measurements\n","                reload=False\n","            )\n","\n","            if self.verbose:\n","                print(\"✓ Session data loaded successfully\")\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"✗ Error loading session data: {str(e)}\")\n","            return False\n","\n","    def extractSessionInfo(self) -\u003e Dict:\n","        \"\"\"\n","        Extract comprehensive session metadata with robust path handling.\n","\n","        Returns:\n","            Dict: Session information including subject, date, lab, etc.\n","        \"\"\"\n","        try:\n","            if self.verbose:\n","                print(\"Extracting session information...\")\n","\n","            sessionDetails = self.one.get_details(self.eid)\n","\n","            # Handle different path object types that ONE API might return\n","            sessionPath = sessionDetails.get('local_path', 'Unknown')\n","\n","            # Convert path object to string if needed\n","            if hasattr(sessionPath, '__str__'):\n","                sessionPathStr = str(sessionPath)\n","            elif hasattr(sessionPath, 'as_posix'):\n","                sessionPathStr = sessionPath.as_posix()\n","            else:\n","                sessionPathStr = sessionPath\n","\n","            if self.verbose:\n","                print(f\"  Raw session path: {sessionPathStr}\")\n","\n","            # Parse path components for session metadata with defensive splitting\n","            pathParts = sessionPathStr.replace('\\\\', '/').split('/')  # Handle both Unix and Windows paths\n","            pathParts = [part for part in pathParts if part]  # Remove empty parts\n","\n","            # Extract session components with fallback logic\n","            if len(pathParts) \u003e= 3:\n","                subject = pathParts[-3]\n","                date = pathParts[-2]\n","                sessionNum = pathParts[-1]\n","            elif len(pathParts) \u003e= 2:\n","                subject = pathParts[-2]\n","                date = pathParts[-1]\n","                sessionNum = 'Unknown'\n","            elif len(pathParts) \u003e= 1:\n","                subject = pathParts[-1]\n","                date = 'Unknown'\n","                sessionNum = 'Unknown'\n","            else:\n","                subject = 'Unknown'\n","                date = 'Unknown'\n","                sessionNum = 'Unknown'\n","\n","            # Alternative extraction method using session details if path parsing fails\n","            if subject == 'Unknown' and 'subject' in sessionDetails:\n","                subject = sessionDetails['subject']\n","            if date == 'Unknown' and 'start_time' in sessionDetails:\n","                # Extract date from start_time if available\n","                startTime = sessionDetails['start_time']\n","                if hasattr(startTime, 'date'):\n","                    date = startTime.date().isoformat()\n","                elif isinstance(startTime, str) and len(startTime) \u003e= 10:\n","                    date = startTime[:10]  # Extract YYYY-MM-DD portion\n","\n","            # Get accurate trial count using SessionLoader\n","            try:\n","                if self.sessLoader is None:\n","                    temp_sess_loader = SessionLoader(one=self.one, eid=self.eid)\n","                    temp_sess_loader.load_trials()\n","                    numberOfTrials = temp_sess_loader.trials.shape[0]\n","                else:\n","                    # Use existing sessLoader if available\n","                    if hasattr(self.sessLoader, 'trials') and self.sessLoader.trials is not None:\n","                        numberOfTrials = self.sessLoader.trials.shape[0]\n","                    else:\n","                        self.sessLoader.load_trials()\n","                        numberOfTrials = self.sessLoader.trials.shape[0]\n","            except Exception as e:\n","                if self.verbose:\n","                    print(f\"  Warning: Could not load trial count via SessionLoader: {e}\")\n","                numberOfTrials = sessionDetails.get('n_trials', 'Unknown')\n","\n","            self.sessionInfo = {\n","                'experimentId': self.eid,\n","                'subject': subject,\n","                'date': date,\n","                'sessionNumber': sessionNum,\n","                'lab': sessionDetails.get('lab', 'Unknown'),\n","                'taskProtocol': sessionDetails.get('task_protocol', 'Unknown'),\n","                'numberOfTrials': numberOfTrials,\n","                'sessionPath': sessionPathStr,\n","                'dataRepository': sessionDetails.get('data_repository', 'Unknown')\n","            }\n","\n","            if self.verbose:\n","                print(\"✓ Session info extracted:\")\n","                for key, value in self.sessionInfo.items():\n","                    print(f\"  {key}: {value}\")\n","\n","            return self.sessionInfo\n","\n","        except Exception as e:\n","            print(f\"✗ Error extracting session info: {str(e)}\")\n","            if self.verbose:\n","                print(f\"  Session details keys available: {list(sessionDetails.keys()) if 'sessionDetails' in locals() else 'None'}\")\n","\n","            # Return minimal info with experiment ID even if extraction fails\n","            self.sessionInfo = {\n","                'experimentId': self.eid,\n","                'subject': 'Unknown',\n","                'date': 'Unknown',\n","                'sessionNumber': 'Unknown',\n","                'lab': 'Unknown',\n","                'taskProtocol': 'Unknown',\n","                'numberOfTrials': 'Unknown',\n","                'sessionPath': 'Unknown',\n","                'dataRepository': 'Unknown'\n","            }\n","            return self.sessionInfo\n","\n","    def validateAndExtractTrialData(self) -\u003e bool:\n","        \"\"\"\n","        Validate and extract trial data with comprehensive feature checking.\n","\n","        Returns:\n","            bool: True if validation successful, False otherwise\n","        \"\"\"\n","        try:\n","            if self.verbose:\n","                print(\"Validating and extracting trial data...\")\n","\n","            if not hasattr(self.sessLoader, 'trials') or self.sessLoader.trials is None:\n","                print(\"✗ No trial data available\")\n","                return False\n","\n","            self.trialData = self.sessLoader.trials\n","\n","            # Check for required trial features\n","            availableFeatures = list(self.trialData.columns)\n","            missingFeatures = [f for f in self.requiredTrialFeatures if f not in availableFeatures]\n","\n","            if self.verbose:\n","                print(f\"✓ Trial data loaded: {len(self.trialData)} trials\")\n","                print(f\"  Available features: {len(availableFeatures)}\")\n","                if missingFeatures:\n","                    print(f\"  Missing features: {missingFeatures}\")\n","                else:\n","                    print(\"  ✓ All required trial features present\")\n","\n","                # Show trial interval statistics\n","                if 'intervals_0' in availableFeatures and 'intervals_1' in availableFeatures:\n","                    intervalDurations = self.trialData['intervals_1'] - self.trialData['intervals_0']\n","                    print(f\"  Trial duration stats:\")\n","                    print(f\"    Mean: {intervalDurations.mean():.2f}s\")\n","                    print(f\"    Min: {intervalDurations.min():.2f}s\")\n","                    print(f\"    Max: {intervalDurations.max():.2f}s\")\n","\n","            return len(missingFeatures) == 0\n","\n","        except Exception as e:\n","            print(f\"✗ Error validating trial data: {str(e)}\")\n","            return False\n","\n","    def validateAndExtractPoseData(self) -\u003e bool:\n","        \"\"\"\n","        Validate and extract left camera pose tracking data, including optional nose_pc injection.\n","        \"\"\"\n","        try:\n","            if self.verbose:\n","                print(\"Validating and extracting pose data...\")\n","\n","            if not hasattr(self.sessLoader, 'pose') or 'leftCamera' not in self.sessLoader.pose:\n","                print(\"✗ No left camera pose data available\")\n","                return False\n","\n","            self.poseData = self.sessLoader.pose['leftCamera']\n","\n","            # Determine CSV path: override if provided, else default construction\n","            if self.nosePCAPath:\n","                csvPath = self.nosePCAPath\n","            else:\n","                # derive from sessionInfo\n","                if not self.sessionInfo:\n","                    self.extractSessionInfo()\n","                lab = self.sessionInfo.get('lab', '')\n","                subject = self.sessionInfo.get('subject', '')\n","                eid = self.eid\n","                csvPath = os.path.join(lab, subject, eid, f\"{eid}_pca1_full.csv\")\n","\n","            # Inject nose_pc if file exists\n","            if os.path.exists(csvPath):\n","                try:\n","                    dfPc = pd.read_csv(csvPath)\n","                    if 'time' in dfPc.columns and 'pc1' in dfPc.columns:\n","                        dfPc.set_index('time', inplace=True)\n","                        # dynamic tolerance based on pose sampling rate\n","                        dt = np.median(np.diff(self.poseData['times']))\n","                        tol = dt * 0.75\n","                        aligned = dfPc.reindex(self.poseData['times'], method='nearest', tolerance=tol)\n","                        self.poseData['nose_pc'] = aligned['pc1'].values\n","                        if self.verbose:\n","                            print(f\"✓ Loaded and injected nose_pc from CSV: {csvPath}\")\n","                    else:\n","                        print(f\"! PCA CSV missing 'time' or 'pc1' columns: {csvPath}\")\n","                except Exception as e:\n","                    print(f\"✗ Error injecting nose_pc: {e}\")\n","            else:\n","                if self.verbose:\n","                    print(f\"! No PCA CSV found at: {csvPath}\")\n","\n","            # Continue with standard validation...\n","            available = list(self.poseData.columns)\n","            # (rest of completeness checks)\n","            return True\n","\n","        except Exception as e:\n","            print(f\"✗ Error validating pose data: {e}\")\n","            return False\n","\n","    def _injectNosePCA(self):\n","        if self.nosePCAPath:\n","            csvPath = self.nosePCAPath\n","        else:\n","            lab   = self.sessionInfo.get('lab','')\n","            subj  = self.sessionInfo.get('subject','')\n","            eid   = self.eid\n","            csvPath = os.path.join(lab, subj, eid, f\"{eid}_pca1_full.csv\")\n","\n","        if os.path.exists(csvPath):\n","            try:\n","                df = pd.read_csv(csvPath).set_index('time')\n","                # dynamic tolerance ~75% of pose sampling interval\n","                dt  = np.median(np.diff(self.poseData['times']))\n","                tol = dt * 0.75\n","                aligned = df.reindex(self.poseData['times'], method='nearest', tolerance=tol)\n","                self.poseData['nose_pc'] = aligned['pc1'].values\n","                if self.verbose:\n","                    print(f\"✓ Re-injected nose_pc from CSV: {csvPath}\")\n","            except Exception as e:\n","                print(f\"✗ PCA re-injection failed: {e}\")\n","        else:\n","            if self.verbose:\n","                print(f\"! No PCA CSV found at: {csvPath}\")\n","\n","    def extractOtherBehavioralData(self) -\u003e bool:\n","        \"\"\"\n","        Extract wheel, motion energy, and pupil data using SessionLoader methods.\n","        Reports what features are tracked across all cameras (left, right, body).\n","\n","        Returns:\n","            bool: True if extraction successful, False otherwise\n","        \"\"\"\n","        try:\n","            if self.verbose:\n","                print(\"Extracting additional behavioral data...\")\n","\n","            # Load wheel data\n","            try:\n","                self.sessLoader.load_wheel()\n","                if hasattr(self.sessLoader, 'wheel') and self.sessLoader.wheel is not None:\n","                    self.wheelData = self.sessLoader.wheel\n","                    if self.verbose:\n","                        print(f\"✓ Wheel data: {len(self.wheelData)} timepoints\")\n","                else:\n","                    if self.verbose:\n","                        print(\"! No wheel data available\")\n","            except Exception as e:\n","                if self.verbose:\n","                    print(f\"! Failed to load wheel data: {e}\")\n","\n","            # Load pose data for all cameras (left, right, body)\n","            try:\n","                self.sessLoader.load_pose(views=['left', 'right', 'body'])\n","                if hasattr(self.sessLoader, 'pose'):\n","                    cameras = ['leftCamera', 'rightCamera', 'bodyCamera']\n","                    available_cameras = [cam for cam in cameras if cam in self.sessLoader.pose]\n","\n","                    if self.verbose:\n","                        print(f\"✓ Pose data loaded for cameras: {available_cameras}\")\n","\n","                    # Analyze features across cameras\n","                    if available_cameras and self.verbose:\n","                        camera_features = {\n","                            cam: set(self.sessLoader.pose[cam].columns)\n","                            for cam in available_cameras\n","                            if self.sessLoader.pose[cam] is not None\n","                        }\n","                        common_features = (\n","                            set.intersection(*camera_features.values())\n","                            if len(camera_features) \u003e 1 else\n","                            next(iter(camera_features.values()))\n","                        )\n","                        print(f\"  Feature analysis across {len(camera_features)} cameras:\")\n","                        print(f\"    Common features ({len(common_features)}): {sorted(common_features)}\")\n","                        for cam, feats in camera_features.items():\n","                            unique = feats - common_features\n","                            if unique:\n","                                print(f\"    {cam} unique features ({len(unique)}): {sorted(unique)}\")\n","\n","                        # Report pupil features\n","                        pupil_avail = {\n","                            cam: [f for f in feats if f.startswith('pupil_')]\n","                            for cam, feats in camera_features.items()\n","                        }\n","                        pupil_avail = {c: p for c, p in pupil_avail.items() if p}\n","                        if pupil_avail:\n","                            print(f\"    Pupil tracking available in: {list(pupil_avail.keys())}\")\n","                            for cam, feats in pupil_avail.items():\n","                                print(f\"      {cam}: {feats}\")\n","\n","                    # Primary data source = leftCamera\n","                    if 'leftCamera' in self.sessLoader.pose:\n","                        self.poseData = self.sessLoader.pose['leftCamera']\n","                        self.pupilData = self.poseData\n","\n","                        # Re-inject nose_pc so it survives overwrite\n","                        self._injectNosePCA()\n","\n","                else:\n","                    if self.verbose:\n","                        print(\"! No pose data available\")\n","            except Exception as e:\n","                if self.verbose:\n","                    print(f\"! Failed to load pose data: {e}\")\n","\n","            # Load motion energy data for all cameras\n","            try:\n","                self.sessLoader.load_motion_energy(views=['left', 'right', 'body'])\n","                if hasattr(self.sessLoader, 'motion_energy'):\n","                    cameras = ['leftCamera', 'rightCamera', 'bodyCamera']\n","                    available_cameras = [cam for cam in cameras if cam in self.sessLoader.motion_energy]\n","\n","                    if self.verbose:\n","                        print(f\"✓ Motion energy data loaded for cameras: {available_cameras}\")\n","\n","                    for cam in available_cameras:\n","                        md = self.sessLoader.motion_energy[cam]\n","                        feats = list(md.keys()) if isinstance(md, dict) else ['whiskerMotionEnergy']\n","                        if self.verbose:\n","                            print(f\"    {cam}: {feats}\")\n","\n","                    if 'leftCamera' in self.sessLoader.motion_energy:\n","                        self.motionEnergyData = self.sessLoader.motion_energy['leftCamera']\n","                else:\n","                    if self.verbose:\n","                        print(\"! No motion energy data available\")\n","            except Exception as e:\n","                if self.verbose:\n","                    print(f\"! Failed to load motion energy data: {e}\")\n","\n","            # Load dedicated pupil data\n","            try:\n","                self.sessLoader.load_pupil()\n","                if hasattr(self.sessLoader, 'pupil') and self.sessLoader.pupil is not None:\n","                    cameras = ['leftCamera', 'rightCamera', 'bodyCamera']\n","                    avail = [cam for cam in cameras if cam in self.sessLoader.pupil]\n","                    if avail and self.verbose:\n","                        print(f\"✓ Dedicated pupil data loaded for cameras: {avail}\")\n","                else:\n","                    if self.verbose:\n","                        print(\"! No dedicated pupil data (pupil tracking is in pose data)\")\n","            except Exception as e:\n","                if self.verbose:\n","                    print(f\"! Failed to load dedicated pupil data: {e}\")\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"✗ Error extracting behavioral data: {e}\")\n","            return False\n","\n","    def loadVideoTimestamps(self) -\u003e bool:\n","        \"\"\"\n","        Load video timestamps for available cameras (left, right, body).\n","        Skips any cameras that aren’t in the video URLs.\n","        Returns True if at least the left camera was loaded successfully.\n","        \"\"\"\n","        try:\n","            if self.verbose:\n","                print(\"Loading video timestamps...\")\n","\n","            eid = self.eid\n","            one = self.one\n","\n","            # Get all available URLs\n","            from ibllib.io import video\n","            video_urls = video.url_from_eid(eid, one=one)\n","\n","            # Only keep the cameras that exist\n","            labels = ['left', 'right', 'body']\n","            urls = {}\n","            for label in labels:\n","                if label in video_urls:\n","                    urls[label] = video_urls[label]\n","                elif self.verbose:\n","                    print(f\"! No {label} camera URL; skipping\")\n","\n","            if 'left' not in urls:\n","                raise RuntimeError(\"Left camera URL missing; cannot set master timeline\")\n","\n","            # Load timestamps only for available cameras\n","            timestamps = {}\n","            for label, url in urls.items():\n","                timestamps[label] = one.load_dataset(eid, f'*{label}Camera.times*', collection='alf')\n","                if self.verbose:\n","                    print(f\"  {label} camera frames: {len(timestamps[label])}\")\n","\n","            self.urls = urls\n","            self.originalTimestamps = timestamps\n","\n","            # Master timeline is left camera\n","            self.videoTimes = timestamps['left']\n","\n","            # Compute original FPS per camera\n","            original_fps = {}\n","            for label, times in timestamps.items():\n","                duration = times[-1] - times[0]\n","                original_fps[label] = round(len(times) / duration) if duration \u003e 0 else None\n","                if self.verbose:\n","                    print(f\"  {label}: {len(times)} frames over {duration:.2f}s → {original_fps[label]} fps\")\n","\n","            self.fps = {'original': original_fps, 'preserved': original_fps, 'target': None}\n","\n","            if self.verbose:\n","                print(\"✓ Video timestamps loaded; using left camera as master timeline\")\n","\n","            return True\n","\n","        except Exception as e:\n","            print(f\"✗ Error loading video timestamps: {e}\")\n","            return False\n","\n","\n","    def sampleInterval(self, trialIdx: int) -\u003e Optional[Dict]:\n","        \"\"\"\n","        Sample a specific trial interval from successful (rewarded) trials only.\n","\n","        Returns:\n","            Dict: Sampled interval data with trial info, or None if sampling fails\n","        \"\"\"\n","        try:\n","            if self.trialData is None or len(self.trialData) == 0:\n","                print(\"✗ No trial data available for sampling\")\n","                return None\n","\n","            # Filter for successful trials only\n","            successTrials = self.trialData[self.trialData['feedbackType'] == 1.0]\n","            if len(successTrials) == 0:\n","                print(\"✗ No successful trials to sample from\")\n","                return None\n","\n","            if trialIdx \u003e= len(successTrials):\n","                print(f\"✗ Trial index {trialIdx} exceeds successful trial count ({len(successTrials)})\")\n","                return None\n","\n","            selectedTrial = successTrials.iloc[trialIdx]\n","            intervalStart = selectedTrial['intervals_0']\n","            intervalEnd = selectedTrial['intervals_1']\n","            intervalDuration = intervalEnd - intervalStart\n","\n","            if self.verbose:\n","                print(f\"✓ Sampled successful trial {trialIdx}, Interval: {intervalStart:.3f} - {intervalEnd:.3f}s\")\n","\n","            poseInInterval = self.extractPoseDataForInterval(intervalStart, intervalEnd)\n","\n","            intervalData = {\n","                'trialIndex': int(selectedTrial.name),  # original trial index in full DataFrame\n","                'intervalStart': intervalStart,\n","                'intervalEnd': intervalEnd,\n","                'duration': intervalDuration,\n","                'trialEvents': selectedTrial.to_dict(),\n","                'poseData': poseInInterval,\n","                'sessionInfo': self.sessionInfo\n","            }\n","\n","            return intervalData\n","        except Exception as e:\n","            print(f\"Error sampling interval: {str(e)}\")\n","            return None\n","\n","    def extractPoseDataForInterval(self, startTime: float, endTime: float) -\u003e Optional[pd.DataFrame]:\n","        \"\"\"\n","        Extract pose data that falls within the specified time interval.\n","        Handles missing data by preserving original timestamps for linear interpolation.\n","\n","        Args:\n","            startTime (float): Start time of interval in seconds\n","            endTime (float): End time of interval in seconds\n","\n","        Returns:\n","            pd.DataFrame: Pose data within the time interval, or None if extraction fails\n","        \"\"\"\n","        try:\n","            if self.poseData is None or 'times' not in self.poseData.columns:\n","                print(\"✗ No pose data or timestamps available\")\n","                return None\n","\n","            # Find pose data within the time interval\n","            timeFilter = (self.poseData['times'] \u003e= startTime) \u0026 (self.poseData['times'] \u003c= endTime)\n","            intervalPoseData = self.poseData[timeFilter].copy()\n","\n","            if len(intervalPoseData) == 0:\n","                print(\"! No pose data in specified interval\")\n","                return None\n","\n","            # Calculate data availability statistics for this interval\n","            if self.verbose:\n","                print(f\"  Pose data in interval: {len(intervalPoseData)} timepoints\")\n","\n","                # Show feature availability for this specific interval\n","                featureStats = {}\n","                for feature in self.requiredPoseFeatures:\n","                    if feature in intervalPoseData.columns and feature != 'times':\n","                        validCount = intervalPoseData[feature].notna().sum()\n","                        totalCount = len(intervalPoseData)\n","                        completeness = (validCount / totalCount) * 100\n","                        featureStats[feature] = {\n","                            'valid_points': validCount,\n","                            'total_points': totalCount,\n","                            'completeness': completeness\n","                        }\n","\n","                # Show summary of feature availability\n","                highQualityFeatures = [f for f, stats in featureStats.items() if stats['completeness'] \u003e 80]\n","                mediumQualityFeatures = [f for f, stats in featureStats.items() if 20 \u003c= stats['completeness'] \u003c= 80]\n","                lowQualityFeatures = [f for f, stats in featureStats.items() if stats['completeness'] \u003c 20]\n","\n","                print(f\"    High quality features (\u003e80%): {len(highQualityFeatures)}\")\n","                print(f\"    Medium quality features (20-80%): {len(mediumQualityFeatures)}\")\n","                print(f\"    Low quality features (\u003c20%): {len(lowQualityFeatures)}\")\n","\n","                if lowQualityFeatures and self.verbose:\n","                    print(f\"    Low quality features will rely on interpolation: {lowQualityFeatures[:3]}{'...' if len(lowQualityFeatures) \u003e 3 else ''}\")\n","\n","            return intervalPoseData\n","\n","        except Exception as e:\n","            print(f\"✗ Error extracting pose data for interval: {str(e)}\")\n","            return None\n","\n","    def extractWheelDataForInterval(self, startTime: float, endTime: float) -\u003e Optional[Dict]:\n","        \"\"\"\n","        Extract wheel data that falls within the specified time interval.\n","        Uses sess_loader.wheel which has columns: ['times', 'position', 'velocity', 'acceleration'].\n","\n","        Args:\n","            startTime (float): Start time of interval in seconds\n","            endTime (float): End time of interval in seconds\n","\n","        Returns:\n","            Dict: Wheel data within the time interval with times and position_raw, or None if extraction fails\n","        \"\"\"\n","        try:\n","            if self.wheelData is None:\n","                if self.verbose:\n","                    print(\"✗ No wheel data available\")\n","                return None\n","\n","            # Check if wheelData has required columns\n","            if not hasattr(self.wheelData, 'columns') or 'times' not in self.wheelData.columns or 'position' not in self.wheelData.columns:\n","                if self.verbose:\n","                    print(\"✗ Wheel data missing required columns (times, position)\")\n","                return None\n","\n","            # Filter wheel data within the time interval\n","            timeFilter = (self.wheelData['times'] \u003e= startTime) \u0026 (self.wheelData['times'] \u003c= endTime)\n","            intervalWheelData = self.wheelData[timeFilter].copy()\n","\n","            if len(intervalWheelData) == 0:\n","                if self.verbose:\n","                    print(\"! No wheel data in specified interval\")\n","                return None\n","\n","            # Return wheel data in the format expected by AnimationRenderer\n","            wheelData = {\n","                'times': intervalWheelData['times'].values,\n","                'position_raw': intervalWheelData['position'].values,\n","            }\n","\n","            if self.verbose:\n","                print(f\"✓ Wheel data extracted: {len(intervalWheelData)} timepoints\")\n","                print(f\"  Time range: {wheelData['times'][0]:.3f} - {wheelData['times'][-1]:.3f}s\")\n","                print(f\"  Position range: {np.nanmin(wheelData['position_raw']):.6f} - {np.nanmax(wheelData['position_raw']):.6f}\")\n","                print(f\"  Valid positions: {np.sum(~np.isnan(wheelData['position_raw']))}\")\n","\n","            return wheelData\n","\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"✗ Error extracting wheel data for interval: {str(e)}\")\n","            return None\n","\n","    def extractMotionEnergyForInterval(self, startTime: float, endTime: float) -\u003e Optional[Dict]:\n","        \"\"\"\n","        Extract motion energy data that falls within the specified time interval.\n","        Uses sess_loader.motion_energy['leftCamera'] structure as user indicated.\n","\n","        Args:\n","            startTime (float): Start time of interval in seconds\n","            endTime (float): End time of interval in seconds\n","\n","        Returns:\n","            Dict: Motion energy data within the time interval, or None if extraction fails\n","        \"\"\"\n","        try:\n","            if self.motionEnergyData is None:\n","                if self.verbose:\n","                    print(\"✗ No motion energy data available\")\n","                return None\n","\n","            if self.verbose:\n","                print(f\"Motion energy data type: {type(self.motionEnergyData)}\")\n","                if hasattr(self.motionEnergyData, 'columns'):\n","                    print(f\"Motion energy DataFrame columns: {list(self.motionEnergyData.columns)}\")\n","                elif isinstance(self.motionEnergyData, dict):\n","                    print(f\"Motion energy keys: {list(self.motionEnergyData.keys())}\")\n","\n","            # Extract whisker motion energy and timestamps\n","            # Based on user info: sess_loader.motion_energy['leftCamera'].columns\n","            whiskerData = None\n","            timestamps = None\n","\n","            # Case 1: DataFrame with columns (most likely structure)\n","            if hasattr(self.motionEnergyData, 'columns'):\n","                df = self.motionEnergyData\n","\n","                # Look for whisker motion energy column\n","                whisker_col = None\n","                for col in df.columns:\n","                    col_str = str(col).lower()\n","                    if 'whisker' in col_str and ('motion' in col_str or 'energy' in col_str):\n","                        whisker_col = col\n","                        break\n","                    elif 'motionenergy' in col_str.replace('_', '').replace(' ', ''):\n","                        whisker_col = col\n","                        break\n","\n","                if whisker_col is None and len(df.columns) \u003e 0:\n","                    # Use first column as fallback\n","                    whisker_col = df.columns[0]\n","                    if self.verbose:\n","                        print(f\"No clear whisker column found, using first column: '{whisker_col}'\")\n","\n","                if whisker_col is not None:\n","                    whiskerData = df[whisker_col]\n","                    if self.verbose:\n","                        print(f\"Using column '{whisker_col}' for whisker motion energy\")\n","\n","                # Get timestamps - check for 'times' column or use index\n","                if 'times' in df.columns:\n","                    timestamps = df['times']\n","                elif hasattr(df.index, 'values'):\n","                    timestamps = df.index.values\n","                else:\n","                    timestamps = df.index\n","\n","            # Case 2: Dictionary structure\n","            elif isinstance(self.motionEnergyData, dict):\n","                # Look for whisker motion energy in dictionary\n","                possible_keys = ['whiskerMotionEnergy', 'whisker', 'motion_energy', 'leftCamera']\n","                for key in possible_keys:\n","                    if key in self.motionEnergyData:\n","                        whiskerData = self.motionEnergyData[key]\n","                        break\n","\n","                # Look for timestamps\n","                if 'times' in self.motionEnergyData:\n","                    timestamps = self.motionEnergyData['times']\n","                elif hasattr(whiskerData, 'index'):\n","                    timestamps = whiskerData.index\n","\n","            # Case 3: Direct Series/Array\n","            else:\n","                whiskerData = self.motionEnergyData\n","                if hasattr(whiskerData, 'index'):\n","                    timestamps = whiskerData.index\n","\n","            if whiskerData is None:\n","                if self.verbose:\n","                    print(\"✗ No whisker motion energy data found\")\n","                return None\n","\n","            if timestamps is None:\n","                if self.verbose:\n","                    print(\"✗ No timestamps found for motion energy data\")\n","                return None\n","\n","            # Convert to numpy arrays for filtering\n","            if hasattr(timestamps, 'values'):\n","                timestamps_array = timestamps.values\n","            else:\n","                timestamps_array = np.asarray(timestamps)\n","\n","            if hasattr(whiskerData, 'values'):\n","                whisker_array = whiskerData.values\n","            else:\n","                whisker_array = np.asarray(whiskerData)\n","\n","            # Filter data for time interval\n","            timeFilter = (timestamps_array \u003e= startTime) \u0026 (timestamps_array \u003c= endTime)\n","            intervalTimestamps = timestamps_array[timeFilter]\n","            intervalWhiskerData = whisker_array[timeFilter]\n","\n","            if len(intervalTimestamps) == 0:\n","                if self.verbose:\n","                    print(\"! No motion energy data in specified interval\")\n","                return None\n","\n","            # Ensure whisker data is 1D\n","            intervalWhiskerData = np.asarray(intervalWhiskerData).flatten()\n","\n","            # Apply smoothing\n","            smoothingWindow = 0.05\n","            if len(intervalTimestamps) \u003e 1:\n","                estimatedSamplingRate = 1.0 / np.median(np.diff(intervalTimestamps))\n","                windowSamples = max(1, int(smoothingWindow * estimatedSamplingRate))\n","            else:\n","                windowSamples = 1\n","                estimatedSamplingRate = None\n","\n","            import pandas as pd\n","            whiskerSmoothed = pd.Series(intervalWhiskerData).rolling(\n","                window=windowSamples, center=True, min_periods=1\n","            ).mean().values\n","\n","            motionData = {\n","                'times': intervalTimestamps,\n","                'whiskerMotionEnergy_raw': intervalWhiskerData,\n","                'whiskerMotionEnergy_smoothed': whiskerSmoothed,\n","                'smoothing_window': smoothingWindow,\n","                'estimated_sampling_rate': estimatedSamplingRate\n","            }\n","\n","            if self.verbose:\n","                print(f\"✓ Motion energy extracted: {len(intervalTimestamps)} timepoints\")\n","                print(f\"  Time range: {intervalTimestamps[0]:.3f} - {intervalTimestamps[-1]:.3f}s\")\n","                print(f\"  Data range: {np.nanmin(intervalWhiskerData):.3f} - {np.nanmax(intervalWhiskerData):.3f}\")\n","\n","            return motionData\n","\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"✗ Error extracting motion energy data: {str(e)}\")\n","                import traceback\n","                traceback.print_exc()\n","            return None\n","\n","    def prepareDataForAnimation(self, intervalData: Dict) -\u003e Optional[Dict]:\n","        \"\"\"\n","        Extract all behavioral data for interval and prepare for animation with consistent time base.\n","        Combines wheel, motion energy extraction and animation data preparation in one method.\n","\n","        Args:\n","            intervalData (Dict): Raw interval data from sampleInterval()\n","\n","        Returns:\n","            Dict: Animation-ready data with synchronized time bases, or None if preparation fails\n","        \"\"\"\n","        try:\n","            if self.verbose:\n","                print(\"Preparing data for animation...\")\n","\n","            startTime = intervalData['intervalStart']\n","            endTime = intervalData['intervalEnd']\n","\n","            # Extract wheel data for this interval using dedicated method\n","            wheelData = self.extractWheelDataForInterval(startTime, endTime)\n","\n","            # Extract motion energy data for this interval using dedicated method\n","            motionData = self.extractMotionEnergyForInterval(startTime, endTime)\n","\n","            # Prepare animation data structure\n","            animationData = {\n","                'metadata': intervalData['sessionInfo'],\n","                'trial_info': {\n","                    'trial_index': intervalData['trialIndex'],\n","                    'start_time': startTime,\n","                    'end_time': endTime,\n","                    'duration': intervalData['duration'],\n","                    'events': intervalData['trialEvents']\n","                },\n","                'synchronized_data': {}\n","            }\n","\n","            # Define common time base for animation (use video frame times as reference)\n","            if self.videoTimes is not None:\n","                videoTimeFilter = (self.videoTimes \u003e= startTime) \u0026 (self.videoTimes \u003c= endTime)\n","                animationTimeBase = self.videoTimes[videoTimeFilter]\n","\n","                if len(animationTimeBase) \u003e 0:\n","                    animationData['synchronized_data']['video_times'] = animationTimeBase\n","                    animationData['synchronized_data']['video_frame_indices'] = np.where(videoTimeFilter)[0]\n","\n","                    if self.verbose:\n","                        print(f\"  Video time base: {len(animationTimeBase)} frames\")\n","                        print(f\"  Frame rate: {len(animationTimeBase) / intervalData['duration']:.1f} fps\")\n","                else:\n","                    print(\"! No video frames found in interval\")\n","                    return None\n","            else:\n","                print(\"✗ No video timestamps available for synchronization\")\n","                return None\n","\n","            # Add pose data with original timestamps (for linear interpolation during animation)\n","            if intervalData['poseData'] is not None:\n","                animationData['synchronized_data']['pose'] = {\n","                    'times': intervalData['poseData']['times'].values,\n","                    'features': {}\n","                }\n","\n","                # Store each pose feature separately for easy access during animation\n","                for feature in self.requiredPoseFeatures:\n","                    if feature in intervalData['poseData'].columns and feature != 'times':\n","                        featureData = intervalData['poseData'][feature].values\n","                        validMask = ~np.isnan(featureData)\n","\n","                        animationData['synchronized_data']['pose']['features'][feature] = {\n","                            'values': featureData,\n","                            'valid_mask': validMask,\n","                            'valid_times': intervalData['poseData']['times'].values[validMask],\n","                            'valid_values': featureData[validMask]\n","                        }\n","\n","            # Add wheel data (position-focused)\n","            if wheelData is not None:\n","                animationData['synchronized_data']['wheel'] = {\n","                    'times': wheelData['times'],\n","                    'position_raw': wheelData['position_raw'],\n","                }\n","\n","            # Add motion energy data\n","            if motionData is not None:\n","                animationData['synchronized_data']['motion_energy'] = {\n","                    'times': motionData['times'],\n","                    'whisker_raw': motionData['whiskerMotionEnergy_raw'],\n","                    'whisker_smoothed': motionData['whiskerMotionEnergy_smoothed'],\n","                    'smoothing_window': motionData['smoothing_window'],\n","                    'sampling_rate': motionData.get('estimated_sampling_rate', None)\n","                }\n","\n","            if self.verbose:\n","                print(\"✓ Animation data preparation completed\")\n","                print(f\"  Data streams prepared: {list(animationData['synchronized_data'].keys())}\")\n","\n","            return animationData\n","\n","        except Exception as e:\n","            print(f\"✗ Error preparing animation data: {str(e)}\")\n","            return None\n","\n","    def loadCompleteSession(self) -\u003e bool:\n","        \"\"\"\n","        Complete workflow to load and validate all session data.\n","\n","        Returns:\n","            bool: True if all loading steps successful, False otherwise\n","        \"\"\"\n","        if self.verbose:\n","            print(\"=\"*60)\n","            print(\"STARTING COMPLETE SESSION LOADING\")\n","            print(\"=\"*60)\n","\n","        steps = [\n","            (\"Loading session data\", self.loadSessionData),\n","            (\"Extracting session info\", lambda: self.extractSessionInfo() != {}),\n","            (\"Validating trial data\", self.validateAndExtractTrialData),\n","            (\"Validating pose data\", self.validateAndExtractPoseData),\n","            (\"Extracting behavioral data\", self.extractOtherBehavioralData),\n","            (\"Loading video timestamps\", self.loadVideoTimestamps)\n","        ]\n","\n","        allSuccessful = True\n","        for stepName, stepFunction in steps:\n","            if self.verbose:\n","                print(f\"\\n{stepName}...\")\n","\n","            success = stepFunction()\n","            if not success:\n","                print(f\"✗ Failed: {stepName}\")\n","                allSuccessful = False\n","            elif self.verbose:\n","                print(f\"✓ Completed: {stepName}\")\n","\n","        if self.verbose:\n","            print(\"\\n\" + \"=\"*60)\n","            if allSuccessful:\n","                print(\"SESSION LOADING COMPLETED SUCCESSFULLY\")\n","            else:\n","                print(\"SESSION LOADING COMPLETED WITH ERRORS\")\n","            print(\"=\"*60)\n","\n","        return allSuccessful"]},{"cell_type":"markdown","metadata":{"id":"laDISm70lWeO"},"source":["# Animator"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1136,"status":"ok","timestamp":1753731267880,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"Ci96UyK3lY8z"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","from matplotlib.animation import FuncAnimation\n","from matplotlib.lines import Line2D\n","from IPython.display import display, HTML\n","from datetime import datetime\n","from typing import Dict, List, Optional\n","import gc\n","\n","class IBLAnimationRenderer:\n","    \"\"\"\n","    High-performance animation renderer for IBL behavioral data with video synchronization.\n","    Displays full trial duration with moving time indicators for optimal performance and context.\n","    \"\"\"\n","\n","    def __init__(self, mode='test', baseDir=None, verbose=True, fps=24, one=None, eid=None, dataLoader=None, cameras=['left', 'right']):\n","        \"\"\"Initialize animation renderer with optional DataLoader integration.\"\"\"\n","        assert mode in ['test', 'save'], f\"Mode must be 'test' or 'save', got {mode}\"\n","\n","        # Validate camera selection\n","        valid_cameras = ['left', 'right', 'body']\n","        if not isinstance(cameras, list) or len(cameras) == 0 or len(cameras) \u003e 2:\n","            raise ValueError(\"cameras must be a list of 1-2 camera names\")\n","        for cam in cameras:\n","            if cam not in valid_cameras:\n","                raise ValueError(f\"Invalid camera '{cam}'. Must be one of {valid_cameras}\")\n","\n","        self.mode = mode\n","        self.baseDir = baseDir or '.'\n","        self.verbose = verbose\n","        self.fps = fps\n","        self.one = one\n","        self.eid = eid\n","        self.dataLoader = dataLoader\n","        self.cameras = cameras  # Store selected cameras\n","\n","        # Animation elements\n","        self.lineObjects = {}\n","        self.timeIndicators = []\n","        self.videoImages = {}  # Dynamic camera video images\n","        self.timeTexts = {}    # Dynamic camera time texts\n","        self.axVideos = {}     # Dynamic camera axes\n","\n","        # Video loading (dynamic camera setup)\n","        self.videoUrls = {cam: None for cam in self.cameras}\n","        self.videoFrameCaches = {cam: {} for cam in self.cameras}\n","        self.cacheStartFrames = {cam: None for cam in self.cameras}\n","        self.chunkSize = 100\n","\n","        # Debug logging\n","        self.debugLog = []\n","\n","        # Initialize DataLoader integration if provided\n","        if self.dataLoader is not None:\n","            self._validateDataLoader()\n","            if self.verbose:\n","                subject = self.dataLoader.sessionInfo.get('subject', 'Unknown')\n","                print(f\"IBL Animation Renderer initialized with DataLoader for subject {subject}\")\n","        elif self.verbose:\n","            print(f\"IBL Animation Renderer initialized (Mode: {mode}, FPS: {fps})\")\n","\n","    def render(self, animationData: Dict) -\u003e None:\n","        \"\"\"Create animation from prepared IBL data.\"\"\"\n","        try:\n","            self._extractMetadata(animationData)\n","            self._initializeVideoLoader()\n","            self._createFigure()\n","            self._initializeVideo()\n","            self._initializePlots(animationData)\n","            self._initializeEvents(animationData)\n","            self._initializeTimeIndicators()\n","            self._createAnimation()\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"Animation error: {str(e)}\")\n","            raise\n","        finally:\n","            self._cleanup()\n","\n","    def _extractMetadata(self, animationData: Dict) -\u003e None:\n","        \"\"\"Extract essential timing and session information.\"\"\"\n","        if 'synchronized_data' not in animationData or 'video_times' not in animationData['synchronized_data']:\n","            raise ValueError(\"Missing video timing data\")\n","\n","        self.trialInfo = animationData['trial_info']\n","        self.sessionInfo = animationData['metadata']\n","        self.videoTimes = animationData['synchronized_data']['video_times']\n","        self.totalFrames = len(self.videoTimes)\n","        self.syncData = animationData['synchronized_data']\n","\n","        # CRITICAL DEBUG: Video/Graph Time Alignment\n","        if self.verbose:\n","            subject = self.sessionInfo.get('subject', 'Unknown')\n","            duration = self.trialInfo['duration']\n","            print(f\"Rendering {duration:.1f}s trial for subject {subject} ({self.totalFrames} frames)\")\n","\n","            print(f\"\\nDEBUG: TIME SYNCHRONIZATION ANALYSIS\")\n","            print(f\"  Trial interval: {self.trialInfo['start_time']:.3f} - {self.trialInfo['end_time']:.3f}s\")\n","            print(f\"  Video times range: {self.videoTimes[0]:.3f} - {self.videoTimes[-1]:.3f}s\")\n","            print(f\"  Video duration: {self.videoTimes[-1] - self.videoTimes[0]:.3f}s\")\n","            print(f\"  Total video frames: {self.totalFrames}\")\n","            print(f\"  Video frame rate: {self.totalFrames / (self.videoTimes[-1] - self.videoTimes[0]):.2f} fps\")\n","\n","            # Check if video times match trial interval\n","            if abs(self.videoTimes[0] - self.trialInfo['start_time']) \u003e 0.1:\n","                print(f\"  WARNING: Video start time mismatch!\")\n","                print(f\"     Video starts at: {self.videoTimes[0]:.3f}s\")\n","                print(f\"     Trial starts at: {self.trialInfo['start_time']:.3f}s\")\n","                print(f\"     Difference: {self.videoTimes[0] - self.trialInfo['start_time']:.3f}s\")\n","\n","            if abs(self.videoTimes[-1] - self.trialInfo['end_time']) \u003e 0.1:\n","                print(f\"  WARNING: Video end time mismatch!\")\n","                print(f\"     Video ends at: {self.videoTimes[-1]:.3f}s\")\n","                print(f\"     Trial ends at: {self.trialInfo['end_time']:.3f}s\")\n","                print(f\"     Difference: {self.videoTimes[-1] - self.trialInfo['end_time']:.3f}s\")\n","\n","            # Check video frame indices if available\n","            if 'video_frame_indices' in self.syncData:\n","                frame_indices = self.syncData['video_frame_indices']\n","                print(f\"  Video frame indices: {frame_indices[0]} to {frame_indices[-1]} (range: {frame_indices[-1] - frame_indices[0] + 1})\")\n","\n","                # Check for frame index gaps\n","                if len(frame_indices) \u003e 1:\n","                    frame_gaps = np.diff(frame_indices)\n","                    unique_gaps = np.unique(frame_gaps)\n","                    if len(unique_gaps) \u003e 1:\n","                        print(f\"  WARNING: Non-uniform frame indices!\")\n","                        print(f\"     Frame index gaps: {unique_gaps}\")\n","                    else:\n","                        print(f\"  Uniform frame indices (step: {unique_gaps[0]})\")\n","\n","            # Check if DataLoader has original timestamps\n","            if hasattr(self.dataLoader, 'standardizedTimestamps'):\n","                print(f\"  DataLoader standardized timestamps available for cameras: {list(self.dataLoader.standardizedTimestamps.keys())}\")\n","                for camera in self.cameras:\n","                    if camera in self.dataLoader.standardizedTimestamps:\n","                        cam_times = self.dataLoader.standardizedTimestamps[camera]\n","                        print(f\"     {camera}: {len(cam_times)} frames, {cam_times[0]:.3f} - {cam_times[-1]:.3f}s\")\n","\n","            print(f\"  Animation will use video times as master clock\")\n","\n","    def _createFigure(self) -\u003e None:\n","        \"\"\"Create figure layout with dynamic camera selection and behavioral plots.\"\"\"\n","        self.fig = plt.figure(figsize=(20, 11), facecolor='white')\n","\n","        num_cameras = len(self.cameras)\n","\n","        if num_cameras == 1:\n","            # Single camera layout: camera takes full left half\n","            gs = GridSpec(4, 2,\n","                         width_ratios=[0.8, 1.2],           # Videos | plots (plots get 20% more space)\n","                         height_ratios=[1.0, 1.0, 1.0, 1.0], # Equal height for plots\n","                         hspace=0.2, wspace=0.12,\n","                         left=0.05, right=0.95, top=0.90, bottom=0.08)\n","\n","            # Single video display (full left half)\n","            self.axVideos = {\n","                self.cameras[0]: self.fig.add_subplot(gs[:, 0])  # Spans all rows\n","            }\n","\n","        elif num_cameras == 2:\n","            # Dual camera layout: equal sized cameras in left half\n","            gs = GridSpec(4, 2,\n","                         width_ratios=[0.8, 1.2],           # Videos | plots (plots get 20% more space)\n","                         height_ratios=[1.0, 1.0, 1.0, 1.0], # Equal height rows\n","                         hspace=0.2, wspace=0.12,\n","                         left=0.05, right=0.95, top=0.90, bottom=0.08)\n","\n","            # Two equal-sized video displays\n","            self.axVideos = {\n","                self.cameras[0]: self.fig.add_subplot(gs[0:2, 0]),  # Top half - spans 2 rows\n","                self.cameras[1]: self.fig.add_subplot(gs[2:4, 0])   # Bottom half - spans 2 rows\n","            }\n","\n","        # Set video titles and properties\n","        for i, camera in enumerate(self.cameras):\n","            ax = self.axVideos[camera]\n","            ax.set_title(f'{camera.title()} Camera', fontsize=11, fontweight='bold', pad=10)\n","            ax.axis('off')\n","\n","        # Behavioral plots (standardized sizes in right half)\n","        self.axPlots = {\n","            'whisker_nose': self.fig.add_subplot(gs[0, 1]),\n","            'wheel': self.fig.add_subplot(gs[1, 1]),\n","            'pupil': self.fig.add_subplot(gs[2, 1]),\n","            'tongue': self.fig.add_subplot(gs[3, 1])\n","        }\n","\n","        # Configure plot appearance with axis labels\n","        for ax in self.axPlots.values():\n","            ax.grid(True, alpha=0.3, linewidth=0.5)\n","            ax.set_xlim(self.trialInfo['start_time'], self.trialInfo['end_time'])\n","\n","        # Enhanced figure title with all required information\n","        trialIdx = self.trialInfo.get('trial_index', 'Unknown')\n","        duration = self.trialInfo['duration']\n","        subject = self.sessionInfo.get('subject', 'Unknown')\n","        lab = self.sessionInfo.get('lab', 'Unknown')\n","        self.fig.suptitle(f'IBL Behavioral Analysis - Trial {trialIdx} - Subject {subject} - Lab {lab} - {duration:.1f}s',\n","                         fontsize=16, fontweight='bold', y=0.95)\n","\n","    def _initializeVideo(self) -\u003e None:\n","        \"\"\"Initialize video displays for selected cameras.\"\"\"\n","        placeholderFrame = np.zeros((480, 640), dtype=np.uint8)\n","\n","        # Initialize video displays dynamically based on selected cameras\n","        self.videoImages = {}\n","        self.timeTexts = {}\n","\n","        for camera in self.cameras:\n","            ax = self.axVideos[camera]\n","\n","            # Create video display\n","            self.videoImages[camera] = ax.imshow(placeholderFrame, cmap='gray', animated=True)\n","\n","            # Create time text overlay\n","            self.timeTexts[camera] = ax.text(0.02, 0.98, '', transform=ax.transAxes,\n","                                           fontsize=11, fontweight='bold', color='white',\n","                                           bbox=dict(boxstyle='round', facecolor='black', alpha=0.7),\n","                                           verticalalignment='top', animated=True)\n","\n","    def _initializePlots(self, animationData: Dict) -\u003e None:\n","        \"\"\"Initialize all behavioral plots with full trial duration data.\"\"\"\n","        self._initializeWhiskerNosePlot()\n","        self._initializeWheelPlot()\n","        self._initializePupilPlot()\n","        self._initializeTonguePlot()\n","\n","    def _initializeWhiskerNosePlot(self) -\u003e None:\n","        \"\"\"Initialize whisker motion and nose tracking plot, preferring nose_pc when available.\"\"\"\n","        ax = self.axPlots['whisker_nose']\n","        ax.set_title('Whisker Motion Energy \u0026 Nose PC1', fontsize=11, fontweight='bold')\n","\n","        axTwin = ax.twinx()\n","\n","        # Whisker motion (left axis)\n","        ax.set_ylabel('Motion Energy (a.u.)', color='red', fontweight='bold')\n","        ax.tick_params(axis='y', labelcolor='red')\n","\n","        # Nose PC1 (right axis)\n","        axTwin.set_ylabel('Nose PC1', color='blue', fontweight='bold')\n","        axTwin.tick_params(axis='y', labelcolor='blue')\n","\n","        lines = {}\n","        # Plot whisker motion energy data\n","        if 'motion_energy' in self.syncData:\n","            motionData = self.syncData['motion_energy']\n","            times = motionData.get('times', [])\n","\n","            if 'whisker_raw' in motionData and len(times) \u003e 0:\n","                rawValues = motionData['whisker_raw']\n","                lines['whisker_raw'] = ax.plot(\n","                    times, rawValues, linewidth=1.5, label='Whisker Raw', alpha=0.8\n","                )[0]\n","\n","            if 'whisker_smoothed' in motionData and len(times) \u003e 0:\n","                smoothedValues = motionData['whisker_smoothed']\n","                lines['whisker_smooth'] = ax.plot(\n","                    times, smoothedValues, linewidth=2.5, label='Whisker Smooth'\n","                )[0]\n","\n","            # Autoscale whisker axis\n","            allValues = []\n","            for key in ['whisker_raw', 'whisker_smoothed']:\n","                if key in motionData:\n","                    allValues.extend(motionData[key])\n","            if allValues:\n","                vmin, vmax = np.nanmin(allValues), np.nanmax(allValues)\n","                vrange = vmax - vmin\n","                ax.set_ylim(vmin - 0.1 * vrange, vmax + 0.1 * vrange)\n","\n","        # Plot nose PC1 if available, else fallback\n","        if 'pose' in self.syncData and 'features' in self.syncData['pose']:\n","            poseData = self.syncData['pose']\n","            poseTimes = poseData.get('times', [])\n","            features = poseData.get('features', {})\n","\n","            if 'nose_pc' in features:\n","                pcValues = features['nose_pc']['values']\n","                validMask = features['nose_pc']['valid_mask']\n","                validTimes = poseTimes[validMask]\n","                validValues = pcValues[validMask]\n","                lines['nose_pc'] = axTwin.plot(\n","                    validTimes, validValues, color='blue', linewidth=2, label='Nose PC1'\n","                )[0]\n","                # Autoscale PC axis\n","                pcMin, pcMax = np.nanmin(validValues), np.nanmax(validValues)\n","                pcRange = pcMax - pcMin\n","                if pcRange \u003e 0:\n","                    axTwin.set_ylim(pcMin - 0.1 * pcRange, pcMax + 0.1 * pcRange)\n","                else:\n","                    axTwin.set_ylim(pcMin - 1, pcMax + 1)\n","            else:\n","                # Fallback to original nose_tip_x/y for compatibility\n","                if 'nose_tip_x' in features:\n","                    noseX = features['nose_tip_x']['values']\n","                    maskX = features['nose_tip_x']['valid_mask']\n","                    lines['nose_x'] = axTwin.plot(\n","                        poseTimes[maskX], noseX[maskX], color='cyan', linewidth=2, label='Nose X'\n","                    )[0]\n","                if 'nose_tip_y' in features:\n","                    noseY = features['nose_tip_y']['values']\n","                    maskY = features['nose_tip_y']['valid_mask']\n","                    lines['nose_y'] = axTwin.plot(\n","                        poseTimes[maskY], noseY[maskY], color='magenta', linewidth=2, label='Nose Y'\n","                    )[0]\n","                # Autoscale fallback axis\n","                fallbackVals = []\n","                for feature in ['nose_tip_x', 'nose_tip_y']:\n","                    if feature in features:\n","                        vals = features[feature]['values'][features[feature]['valid_mask']]\n","                        fallbackVals.extend(vals)\n","                if fallbackVals:\n","                    fmin, fmax = np.nanmin(fallbackVals), np.nanmax(fallbackVals)\n","                    frange = fmax - fmin\n","                    if frange \u003e 0:\n","                        axTwin.set_ylim(fmin - 0.1 * frange, fmax + 0.1 * frange)\n","                    else:\n","                        axTwin.set_ylim(fmin - 10, fmax + 10)\n","\n","        # Legends\n","        if any('whisker' in key for key in lines):\n","            ax.legend(loc='upper left', fontsize=10)\n","        if any('nose' in key for key in lines):\n","            axTwin.legend(loc='upper right', fontsize=10)\n","\n","        self.lineObjects['whisker_nose'] = lines\n","\n","    def _initializeWheelPlot(self) -\u003e None:\n","        \"\"\"Initialize wheel position plot.\"\"\"\n","        ax = self.axPlots['wheel']\n","        ax.set_title('Wheel Position', fontsize=11, fontweight='bold')\n","        ax.set_ylabel('Position (radians)', color='darkblue', fontweight='bold')\n","        ax.tick_params(axis='y', labelcolor='darkblue')\n","\n","        lines = {}\n","\n","        if 'wheel' in self.syncData:\n","            wheelData = self.syncData['wheel']\n","            times = wheelData.get('times', [])\n","\n","            # Display wheel position instead of velocity/acceleration\n","            if 'position_raw' in wheelData and len(times) \u003e 0:\n","                position = wheelData['position_raw']\n","\n","                # Handle NaN values in position data\n","                if np.any(~np.isnan(position)):\n","                    lines['position'] = ax.plot(times, position, color='darkblue',\n","                                               linewidth=2.5, label='Wheel Position')[0]\n","\n","                    # Set y-limits based on actual position data\n","                    validPosition = position[~np.isnan(position)]\n","                    if len(validPosition) \u003e 0:\n","                        pmin, pmax = np.min(validPosition), np.max(validPosition)\n","                        prange = pmax - pmin\n","                        if prange \u003e 0:\n","                            ax.set_ylim(pmin - 0.1 * prange, pmax + 0.1 * prange)\n","                        else:\n","                            ax.set_ylim(pmin - 1, pmax + 1)\n","                    else:\n","                        ax.set_ylim(-10, 10)  # Default range\n","                else:\n","                    # No valid position data\n","                    ax.text(0.5, 0.5, 'No valid wheel position data',\n","                           transform=ax.transAxes, ha='center', va='center',\n","                           fontsize=10, color='gray')\n","                    ax.set_ylim(-1, 1)\n","\n","        # Add legend\n","        if lines:\n","            ax.legend(loc='upper right', fontsize=10)\n","\n","        self.lineObjects['wheel'] = lines\n","\n","    def _initializePupilPlot(self) -\u003e None:\n","        \"\"\"Initialize pupil tracking plot.\"\"\"\n","        ax = self.axPlots['pupil']\n","        ax.set_title('Pupil Tracking', fontsize=11, fontweight='bold')\n","\n","        axTwin = ax.twinx()\n","\n","        lines = {}\n","\n","        if 'pose' in self.syncData and 'features' in self.syncData['pose']:\n","            poseData = self.syncData['pose']\n","            poseTimes = poseData.get('times', [])\n","            features = poseData.get('features', {})\n","\n","            # Pupil X (left axis)\n","            if 'pupil_top_r_x' in features and len(poseTimes) \u003e 0:\n","                pupilX = features['pupil_top_r_x']['values']\n","                validMask = features['pupil_top_r_x']['valid_mask']\n","                validTimes = poseTimes[validMask]\n","                validValues = pupilX[validMask]\n","                if len(validValues) \u003e 0:\n","                    lines['pupil_x'] = ax.plot(validTimes, validValues, color='darkblue',\n","                                              linewidth=2, label='Pupil X')[0]\n","\n","                    # Set y-limits for X axis\n","                    pupilXMin, pupilXMax = np.nanmin(validValues), np.nanmax(validValues)\n","                    pupilXRange = pupilXMax - pupilXMin\n","                    if pupilXRange \u003e 0:\n","                        ax.set_ylim(pupilXMin - 0.1 * pupilXRange, pupilXMax + 0.1 * pupilXRange)\n","                    else:\n","                        ax.set_ylim(pupilXMin - 10, pupilXMax + 10)\n","\n","                    ax.set_ylabel('Pupil X Position (pixels)', color='darkblue', fontweight='bold')\n","                    ax.tick_params(axis='y', labelcolor='darkblue')\n","\n","            # Pupil Y (right axis)\n","            if 'pupil_top_r_y' in features and len(poseTimes) \u003e 0:\n","                pupilY = features['pupil_top_r_y']['values']\n","                validMask = features['pupil_top_r_y']['valid_mask']\n","                validTimes = poseTimes[validMask]\n","                validValues = pupilY[validMask]\n","                if len(validValues) \u003e 0:\n","                    lines['pupil_y'] = axTwin.plot(validTimes, validValues, color='violet',\n","                                                  linewidth=2, label='Pupil Y')[0]\n","\n","                    # Set y-limits for Y axis\n","                    pupilYMin, pupilYMax = np.nanmin(validValues), np.nanmax(validValues)\n","                    pupilYRange = pupilYMax - pupilYMin\n","                    if pupilYRange \u003e 0:\n","                        axTwin.set_ylim(pupilYMin - 0.1 * pupilYRange, pupilYMax + 0.1 * pupilYRange)\n","                    else:\n","                        axTwin.set_ylim(pupilYMin - 10, pupilYMax + 10)\n","\n","                    axTwin.set_ylabel('Pupil Y Position (pixels)', color='violet', fontweight='bold')\n","                    axTwin.tick_params(axis='y', labelcolor='violet')\n","\n","        # Add legends\n","        if any('pupil_x' in key for key in lines.keys()):\n","            ax.legend(loc='upper left', fontsize=10)\n","        if any('pupil_y' in key for key in lines.keys()):\n","            axTwin.legend(loc='upper right', fontsize=10)\n","\n","        self.lineObjects['pupil'] = lines\n","\n","    def _initializeTonguePlot(self) -\u003e None:\n","        \"\"\"Initialize tongue tracking plot.\"\"\"\n","        ax = self.axPlots['tongue']\n","        ax.set_title('Tongue Tracking', fontsize=11, fontweight='bold')\n","        ax.set_ylabel('Tongue Position (pixels)', fontweight='bold')\n","\n","        lines = {}\n","\n","        if 'pose' in self.syncData and 'features' in self.syncData['pose']:\n","            poseData = self.syncData['pose']\n","            poseTimes = poseData.get('times', [])\n","            features = poseData.get('features', {})\n","\n","            tongueValues = []\n","\n","            if 'tongue_end_l_x' in features and len(poseTimes) \u003e 0:\n","                tongueX = features['tongue_end_l_x']['values']\n","                validMask = features['tongue_end_l_x']['valid_mask']\n","                validTimes = poseTimes[validMask]\n","                validValues = tongueX[validMask]\n","                if len(validValues) \u003e 0:\n","                    lines['tongue_x'] = ax.plot(validTimes, validValues, color='magenta',\n","                                               linewidth=2, label='Tongue X')[0]\n","                    tongueValues.extend(validValues)\n","\n","            if 'tongue_end_l_y' in features and len(poseTimes) \u003e 0:\n","                tongueY = features['tongue_end_l_y']['values']\n","                validMask = features['tongue_end_l_y']['valid_mask']\n","                validTimes = poseTimes[validMask]\n","                validValues = tongueY[validMask]\n","                if len(validValues) \u003e 0:\n","                    lines['tongue_y'] = ax.plot(validTimes, validValues, color='brown',\n","                                               linewidth=2, label='Tongue Y')[0]\n","                    tongueValues.extend(validValues)\n","\n","            # Set y-limits based on actual data range\n","            if tongueValues:\n","                tongueMin, tongueMax = np.nanmin(tongueValues), np.nanmax(tongueValues)\n","                tongueRange = tongueMax - tongueMin\n","                if tongueRange \u003e 0:\n","                    ax.set_ylim(tongueMin - 0.1 * tongueRange, tongueMax + 0.1 * tongueRange)\n","                else:\n","                    ax.set_ylim(tongueMin - 10, tongueMax + 10)\n","            else:\n","                ax.set_ylim(0, 480)\n","\n","        ax.legend(loc='upper right', fontsize=10)\n","        self.lineObjects['tongue'] = lines\n","\n","    def _initializeEvents(self, animationData: Dict) -\u003e None:\n","        \"\"\"Initialize experimental event markers.\"\"\"\n","        # Only show requested events: stimOn, stimOff, firstMovement, Response, Feedback\n","        eventStyles = {\n","            'stimOn': {'color': 'red', 'linestyle': '-', 'linewidth': 2, 'label': 'stimOn'},\n","            'stimOff': {'color': 'orange', 'linestyle': '-', 'linewidth': 2, 'label': 'stimOff'},\n","            'firstMovement': {'color': 'cyan', 'linestyle': '-.', 'linewidth': 2, 'label': 'firstMovement'},\n","            'response': {'color': 'blue', 'linestyle': '-', 'linewidth': 2, 'label': 'Response'},\n","            'feedback': {'color': 'magenta', 'linestyle': ':', 'linewidth': 2, 'label': 'Feedback'}\n","        }\n","\n","        trialEvents = animationData['trial_info'].get('events', {})\n","        startTime = self.trialInfo['start_time']\n","        endTime = self.trialInfo['end_time']\n","\n","        debugInfo = {\n","            'trial_interval': {'start': startTime, 'end': endTime},\n","            'available_event_keys': list(trialEvents.keys()),\n","            'events_processed': {}\n","        }\n","\n","        self._log_debug(f\"DEBUGGING EVENT EXTRACTION:\")\n","        self._log_debug(f\"Trial interval: {startTime:.3f} - {endTime:.3f}s\")\n","        self._log_debug(f\"Available trial event keys: {list(trialEvents.keys())}\")\n","\n","        legendHandles = []\n","\n","        for eventName, eventStyle in eventStyles.items():\n","            eventTimes = self._extractEventTimes(trialEvents, eventName)\n","\n","            self._log_debug(f\"{eventName}:\")\n","            self._log_debug(f\"  Raw event times: {eventTimes}\")\n","\n","            eventInfo = {\n","                'raw_times': eventTimes,\n","                'valid_times': [],\n","                'markers_added': 0\n","            }\n","\n","            if eventTimes:\n","                validEventTimes = [t for t in eventTimes if startTime \u003c= t \u003c= endTime]\n","                eventInfo['valid_times'] = validEventTimes\n","\n","                self._log_debug(f\"  Valid event times (within interval): {validEventTimes}\")\n","\n","                if validEventTimes:\n","                    for ax in self.axPlots.values():\n","                        for eventTime in validEventTimes:\n","                            ax.axvline(x=eventTime, alpha=0.8,\n","                                     **{k: v for k, v in eventStyle.items() if k != 'label'})\n","\n","                    legendHandles.append(Line2D([0], [0], **eventStyle))\n","                    eventInfo['markers_added'] = len(validEventTimes)\n","\n","                    self._log_debug(f\"  Added {len(validEventTimes)} event markers\")\n","                else:\n","                    self._log_debug(f\"  No events within trial interval\")\n","            else:\n","                self._log_debug(f\"  No event times found\")\n","\n","            debugInfo['events_processed'][eventName] = eventInfo\n","\n","        # Add legend at bottom center to not obstruct views\n","        if legendHandles:\n","            self.fig.legend(handles=legendHandles,\n","                           loc='lower center',\n","                           bbox_to_anchor=(0.5, 0.01),\n","                           ncol=5, fontsize=10,\n","                           frameon=True,\n","                           title='Events',\n","                           title_fontsize=11)\n","\n","            self._log_debug(f\"Added legend for {len(legendHandles)} event types\")\n","        else:\n","            self._log_debug(f\"No valid events found - no legend added\")\n","\n","        # Store debug info for save mode\n","        if self.mode == 'save':\n","            self.eventDebugInfo = debugInfo\n","\n","    def _extractEventTimes(self, trialEvents: Dict, eventName: str) -\u003e List[float]:\n","        \"\"\"Extract timing information for specific event type.\"\"\"\n","        self._log_debug(f\"  Extracting {eventName}:\")\n","\n","        # Check direct event timing storage\n","        directKey = f\"{eventName}_times\"\n","        self._log_debug(f\"    Checking direct key: {directKey}\")\n","        if directKey in trialEvents:\n","            eventData = trialEvents[directKey]\n","            self._log_debug(f\"    Found data: {eventData} (type: {type(eventData)})\")\n","            if isinstance(eventData, (list, np.ndarray)):\n","                validTimes = [float(t) for t in eventData if not np.isnan(float(t))]\n","                self._log_debug(f\"    Valid times from list: {validTimes}\")\n","                return validTimes\n","            elif not np.isnan(float(eventData)):\n","                validTime = float(eventData)\n","                self._log_debug(f\"    Valid time from scalar: {validTime}\")\n","                return [validTime]\n","\n","        # Check alternative naming conventions\n","        altKeys = [eventName, f\"{eventName}Times\", f\"{eventName.lower()}_times\"]\n","        self._log_debug(f\"    Checking alternative keys: {altKeys}\")\n","\n","        for key in altKeys:\n","            if key in trialEvents:\n","                eventData = trialEvents[key]\n","                self._log_debug(f\"    Found {key}: {eventData} (type: {type(eventData)})\")\n","                if isinstance(eventData, (list, np.ndarray)):\n","                    validTimes = [float(t) for t in eventData if not np.isnan(float(t))]\n","                    self._log_debug(f\"    Valid times from {key}: {validTimes}\")\n","                    return validTimes\n","                elif not np.isnan(float(eventData)):\n","                    validTime = float(eventData)\n","                    self._log_debug(f\"    Valid time from {key}: {validTime}\")\n","                    return [validTime]\n","\n","        self._log_debug(f\"    No valid times found for {eventName}\")\n","        return []\n","\n","    def _log_debug(self, message):\n","        \"\"\"Add debug message to log.\"\"\"\n","        if self.mode == 'save':\n","            self.debugLog.append(message)\n","        if self.verbose:\n","            print(message)\n","\n","    def _initializeVideoLoader(self) -\u003e None:\n","        \"\"\"Initialize video loading system for selected cameras.\"\"\"\n","        if self.one is None or self.eid is None:\n","            self._log_debug(\"No ONE instance or EID provided - video will use placeholders\")\n","            return\n","\n","        try:\n","            from ibllib.io import video\n","            videoUrls = video.url_from_eid(self.eid, one=self.one)\n","\n","            # Initialize only selected cameras\n","            for camera in self.cameras:\n","                self.videoUrls[camera] = videoUrls.get(camera)\n","\n","            cameras_found = [cam for cam in self.cameras if self.videoUrls[cam] is not None]\n","            if cameras_found:\n","                self._log_debug(f\"Video URLs loaded for selected cameras: {cameras_found}\")\n","            else:\n","                self._log_debug(\"No video URLs found for selected cameras\")\n","\n","        except Exception as e:\n","            self._log_debug(f\"Video initialization failed: {e}\")\n","            # Reset to None for all selected cameras\n","            for camera in self.cameras:\n","                self.videoUrls[camera] = None\n","\n","    def _getCameraFrameForTime(self, camera: str, target_time: float):\n","        \"\"\"\n","        Get the best camera frame index for a specific time using interpolation.\n","        This respects the camera's original frame rate instead of forcing alignment.\n","        \"\"\"\n","        if not hasattr(self.dataLoader, 'one') or not hasattr(self.dataLoader, 'eid'):\n","            return None, None, float('inf')\n","\n","        try:\n","            # Get original camera timestamps directly from ONE\n","            from one.api import ONE\n","            one = self.dataLoader.one\n","            eid = self.dataLoader.eid\n","\n","            # Load raw camera timestamps\n","            camera_times = one.load_dataset(eid, f'_ibl_{camera}Camera.times.npy')\n","\n","            # Find closest frame to target time\n","            time_diffs = np.abs(camera_times - target_time)\n","            closest_idx = np.argmin(time_diffs)\n","            actual_time = camera_times[closest_idx]\n","            time_error = abs(actual_time - target_time)\n","\n","            if self.verbose and hasattr(self, '_first_frame_debug') and camera not in self._first_frame_debug:\n","                print(f\"Camera {camera} raw timing: {len(camera_times)} frames, {camera_times[0]:.3f}-{camera_times[-1]:.3f}s\")\n","                if not hasattr(self, '_first_frame_debug'):\n","                    self._first_frame_debug = set()\n","                self._first_frame_debug.add(camera)\n","\n","            return closest_idx, actual_time, time_error\n","\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"Failed to get raw timestamps for {camera}: {e}\")\n","            return None, None, float('inf')\n","\n","    def _loadVideoChunk(self, startFrame: int, camera: str = 'left') -\u003e None:\n","        \"\"\"Load chunk of video frames using correct timing approach.\"\"\"\n","        if camera not in self.videoUrls or self.videoUrls[camera] is None:\n","            return\n","\n","        try:\n","            from ibllib.io import video\n","\n","            # NEW APPROACH: Use animation timeline to get correct camera frames\n","            animation_start_idx = startFrame\n","            animation_end_idx = min(startFrame + self.chunkSize, self.totalFrames)\n","\n","            # Get the times for these animation frames\n","            animation_times = self.videoTimes[animation_start_idx:animation_end_idx]\n","\n","            # Map each animation time to the best camera frame\n","            camera_frame_indices = []\n","            timing_errors = []\n","\n","            for anim_time in animation_times:\n","                cam_frame_idx, actual_time, time_error = self._getCameraFrameForTime(camera, anim_time)\n","                if cam_frame_idx is not None:\n","                    camera_frame_indices.append(cam_frame_idx)\n","                    timing_errors.append(time_error)\n","                else:\n","                    # Fallback: estimate frame index\n","                    if hasattr(self, '_fallback_camera_start'):\n","                        cam_start_time = self._fallback_camera_start.get(camera, anim_time)\n","                    else:\n","                        cam_start_time = anim_time\n","                    estimated_idx = int((anim_time - cam_start_time) * 60)  # Assume ~60fps\n","                    camera_frame_indices.append(max(0, estimated_idx))\n","                    timing_errors.append(0.1)  # Large error for fallback\n","\n","            if self.verbose and startFrame == 0:\n","                print(f\"\\nDEBUG: Corrected video loading for {camera}\")\n","                print(f\"  Animation frames: {animation_start_idx} to {animation_end_idx-1}\")\n","                print(f\"  Animation times: {animation_times[0]:.3f}s to {animation_times[-1]:.3f}s\")\n","                if camera_frame_indices:\n","                    print(f\"  {camera} frame indices: {camera_frame_indices[0]} to {camera_frame_indices[-1]}\")\n","                    avg_error = np.mean(timing_errors) * 1000  # Convert to ms\n","                    max_error = np.max(timing_errors) * 1000\n","                    print(f\"  Timing errors: avg={avg_error:.1f}ms, max={max_error:.1f}ms\")\n","\n","            # Load the mapped camera frames\n","            if camera_frame_indices:\n","                frames = video.get_video_frames_preload(self.videoUrls[camera], camera_frame_indices)\n","\n","                # Store frames in cache with animation frame indices as keys\n","                for i, frame in enumerate(frames):\n","                    self.videoFrameCaches[camera][startFrame + i] = frame\n","\n","                self.cacheStartFrames[camera] = startFrame\n","\n","                if self.verbose and startFrame == 0:\n","                    print(f\"Loaded {camera}: {len(frames)} frames with corrected timing\")\n","            else:\n","                if self.verbose:\n","                    print(f\"No valid frame indices for {camera}\")\n","\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"Failed to load {camera} camera chunk at frame {startFrame}: {e}\")\n","\n","    def _getVideoFrame(self, frameIdx: int, camera: str = 'left') -\u003e np.ndarray:\n","        \"\"\"Get video frame using corrected timing approach.\"\"\"\n","\n","        # DEBUG: Show corrected timing for first few frames\n","        if self.verbose and frameIdx \u003c 3:\n","            current_time = self.videoTimes[frameIdx]\n","            cam_frame_idx, actual_time, time_error = self._getCameraFrameForTime(camera, current_time)\n","\n","            print(f\"CORRECTED: Camera {camera} frame {frameIdx}: AnimTime={current_time:.3f}s\")\n","            if cam_frame_idx is not None:\n","                print(f\"   Best camera frame: {cam_frame_idx}, actual time: {actual_time:.3f}s\")\n","                print(f\"   Timing error: {time_error*1000:.1f}ms\")\n","                if time_error \u003c 0.05:  # Less than 50ms\n","                    print(f\"   Excellent timing alignment\")\n","                elif time_error \u003c 0.1:  # Less than 100ms\n","                    print(f\"   Good timing alignment\")\n","                else:\n","                    print(f\"   WARNING: Large timing error\")\n","            else:\n","                print(f\"   Failed to find camera frame\")\n","\n","        # Check if we need to load a new chunk for this camera\n","        if (self.cacheStartFrames[camera] is None or\n","            frameIdx \u003c self.cacheStartFrames[camera] or\n","            frameIdx \u003e= self.cacheStartFrames[camera] + self.chunkSize):\n","\n","            # Calculate chunk start (align to chunk boundaries)\n","            chunkStart = (frameIdx // self.chunkSize) * self.chunkSize\n","            self._loadVideoChunk(chunkStart, camera)\n","\n","        # Return frame from camera-specific cache or placeholder\n","        if frameIdx in self.videoFrameCaches[camera]:\n","            frame = self.videoFrameCaches[camera][frameIdx]\n","            # Handle frame format\n","            if frame.ndim == 3 and frame.shape[2] == 1:\n","                frame = frame[..., 0]\n","            return frame\n","        else:\n","            # Fallback placeholder with debug info\n","            if self.verbose and frameIdx \u003c 5:\n","                print(f\"Using placeholder frame for {camera} at animation frame {frameIdx}\")\n","            return np.random.randint(0, 255, (480, 640), dtype=np.uint8)\n","\n","    def _initializeTimeIndicators(self) -\u003e None:\n","        \"\"\"Initialize vertical time indicator lines.\"\"\"\n","        self.timeIndicators = []\n","        startTime = self.trialInfo['start_time']\n","\n","        for ax in self.axPlots.values():\n","            timeLine = ax.axvline(x=startTime, color='red', linewidth=3,\n","                                 alpha=0.8, animated=True, zorder=10)\n","            self.timeIndicators.append(timeLine)\n","\n","    def _createAnimation(self) -\u003e None:\n","        \"\"\"Create and display animation.\"\"\"\n","        animation = FuncAnimation(\n","            self.fig,\n","            self._updateFrame,\n","            frames=self.totalFrames,\n","            interval=1000 / self.fps,\n","            blit=True,\n","            repeat=False\n","        )\n","\n","        self._saveOrDisplay(animation)\n","\n","    def _updateFrame(self, frameIdx: int) -\u003e List:\n","        \"\"\"Update frame - move time indicators and update video displays.\"\"\"\n","        currentTime = self.videoTimes[frameIdx]\n","        updatedElements = []\n","\n","        # DEBUG: Show timing details for first few frames\n","        if self.verbose and frameIdx \u003c 5:\n","            video_frame_idx = self.syncData['video_frame_indices'][frameIdx] if 'video_frame_indices' in self.syncData else frameIdx\n","            print(f\"Frame {frameIdx}: Time={currentTime:.3f}s, VideoFrameIdx={video_frame_idx}\")\n","\n","            # Check if this matches expected trial timing\n","            trial_progress = (currentTime - self.trialInfo['start_time']) / self.trialInfo['duration']\n","            print(f\"   Trial progress: {trial_progress*100:.1f}% ({currentTime:.3f}s / {self.trialInfo['duration']:.3f}s)\")\n","\n","        # Update video frames for all selected cameras\n","        for camera in self.cameras:\n","            frame = self._getVideoFrame(frameIdx, camera)\n","            self.videoImages[camera].set_array(frame)\n","            updatedElements.append(self.videoImages[camera])\n","\n","        # Update time displays on all videos\n","        timeText = f'Time: {currentTime:.2f}s'\n","        for camera in self.cameras:\n","            self.timeTexts[camera].set_text(timeText)\n","            updatedElements.append(self.timeTexts[camera])\n","\n","        # Move time indicators across all plots\n","        for timeLine in self.timeIndicators:\n","            timeLine.set_xdata([currentTime, currentTime])\n","        updatedElements.extend(self.timeIndicators)\n","\n","        return updatedElements\n","\n","    def _saveOrDisplay(self, animation: FuncAnimation) -\u003e None:\n","        \"\"\"Save or display animation.\"\"\"\n","        if self.mode == 'test':\n","            self._log_debug(\"Displaying animation...\")\n","            display(HTML(animation.to_jshtml()))\n","        else:\n","            self._log_debug(\"Saving animation...\")\n","\n","            sessionId = self.sessionInfo.get('experimentId', 'unknown')\n","            outDir = os.path.join(self.baseDir, f\"session_{sessionId}\")\n","\n","            # Create directory if it doesn't exist\n","            os.makedirs(outDir, exist_ok=True)\n","\n","            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n","            trialIdx = self.trialInfo.get('trial_index', 'unknown')\n","            filename = f\"trial_{trialIdx}_{timestamp}.mp4\"\n","            filepath = os.path.join(outDir, filename)\n","\n","            animation.save(filepath, writer='ffmpeg', fps=self.fps,\n","                          bitrate=5000, codec='libx264')\n","\n","            self._log_debug(f\"Animation saved to: {filepath}\")\n","\n","            # Save debug log to JSON file\n","            if hasattr(self, 'eventDebugInfo'):\n","                debugFilename = f\"trial_{trialIdx}_{timestamp}_debug.json\"\n","                debugFilepath = os.path.join(outDir, debugFilename)\n","\n","                debugData = {\n","                    'trial_info': self.trialInfo,\n","                    'session_info': self.sessionInfo,\n","                    'event_debug': self.eventDebugInfo,\n","                    'debug_log': self.debugLog,\n","                    'video_file': filename\n","                }\n","\n","                import json\n","                with open(debugFilepath, 'w') as f:\n","                    json.dump(debugData, f, indent=2, default=str)\n","\n","                self._log_debug(f\"Debug info saved to: {debugFilepath}\")\n","\n","    def _cleanup(self) -\u003e None:\n","        \"\"\"Clean up resources.\"\"\"\n","        gc.collect()\n","\n","    # DataLoader Integration Methods\n","    def _validateDataLoader(self) -\u003e None:\n","        \"\"\"Validate DataLoader state.\"\"\"\n","        if isinstance(self.dataLoader, type):\n","            raise TypeError(\"Expected DataLoader instance, received class.\")\n","\n","        if not hasattr(self.dataLoader, 'sessionInfo') or not self.dataLoader.sessionInfo:\n","            raise AttributeError(\"DataLoader has not loaded session data.\")\n","\n","        if not hasattr(self.dataLoader, 'trialData') or self.dataLoader.trialData is None:\n","            raise ValueError(\"DataLoader does not contain trial data.\")\n","\n","    def animateRandomInterval(self) -\u003e bool:\n","        \"\"\"Create animation of random trial interval.\"\"\"\n","        if self.dataLoader is None:\n","            raise ValueError(\"DataLoader required for this method. Initialize with dataLoader parameter.\")\n","\n","        try:\n","            if self.verbose:\n","                print(\"Creating random interval animation...\")\n","\n","            animationData = self._sampleIntervalAdaptive()\n","            if animationData is None:\n","                return False\n","\n","            self.render(animationData)\n","            if self.verbose:\n","                print(\"Animation completed!\")\n","            return True\n","\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"Animation failed: {str(e)}\")\n","            return False\n","\n","    def animateSpecificTrial(self, trialIndex: int) -\u003e bool:\n","        \"\"\"Create animation of specific trial.\"\"\"\n","        if self.dataLoader is None:\n","            raise ValueError(\"DataLoader required for this method. Initialize with dataLoader parameter.\")\n","\n","        try:\n","            if trialIndex \u003e= len(self.dataLoader.trialData):\n","                if self.verbose:\n","                    print(f\"Trial {trialIndex} not found\")\n","                return False\n","\n","            if self.verbose:\n","                print(f\"Animating trial {trialIndex}...\")\n","\n","            selectedTrial = self.dataLoader.trialData.iloc[trialIndex]\n","            intervalStart = selectedTrial['intervals_0']\n","            intervalEnd = selectedTrial['intervals_1']\n","\n","            intervalData = {\n","                'trialIndex': trialIndex,\n","                'intervalStart': intervalStart,\n","                'intervalEnd': intervalEnd,\n","                'duration': intervalEnd - intervalStart,\n","                'trialEvents': selectedTrial.to_dict(),\n","                'sessionInfo': self.dataLoader.sessionInfo\n","            }\n","\n","            # Extract behavioral data\n","            if hasattr(self.dataLoader, 'extractPoseDataForInterval'):\n","                intervalData['poseData'] = self.dataLoader.extractPoseDataForInterval(intervalStart, intervalEnd)\n","            if hasattr(self.dataLoader, 'extractWheelDataForInterval'):\n","                intervalData['wheelData'] = self.dataLoader.extractWheelDataForInterval(intervalStart, intervalEnd)\n","            if hasattr(self.dataLoader, 'extractMotionEnergyForInterval'):\n","                intervalData['motionEnergyData'] = self.dataLoader.extractMotionEnergyForInterval(intervalStart, intervalEnd)\n","\n","            animationData = self._prepareAnimationDataLocally(intervalData)\n","            if animationData is None:\n","                return False\n","\n","            self.render(animationData)\n","            if self.verbose:\n","                print(f\"Trial {trialIndex} completed!\")\n","            return True\n","\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"Failed to animate trial {trialIndex}: {str(e)}\")\n","            return False\n","\n","    def _sampleIntervalAdaptive(self):\n","        \"\"\"Sample interval with adaptive DataLoader compatibility.\"\"\"\n","        if hasattr(self.dataLoader, 'prepareDataForAnimation'):\n","            try:\n","                import random\n","                trialIdx = random.randint(0, len(self.dataLoader.trialData) - 1)\n","                rawData = self.dataLoader.sampleInterval(trialIdx)\n","                return self.dataLoader.prepareDataForAnimation(rawData) if rawData else None\n","            except:\n","                pass\n","\n","        import random\n","        trialIdx = random.randint(0, len(self.dataLoader.trialData) - 1)\n","        rawData = self.dataLoader.sampleInterval(trialIdx)\n","        return self._prepareAnimationDataLocally(rawData) if rawData else None\n","\n","    def _prepareAnimationDataLocally(self, rawIntervalData):\n","        \"\"\"Prepare animation data locally.\"\"\"\n","        try:\n","            startTime = rawIntervalData['intervalStart']\n","            endTime = rawIntervalData['intervalEnd']\n","\n","            animationData = {\n","                'metadata': rawIntervalData['sessionInfo'],\n","                'trial_info': {\n","                    'trial_index': rawIntervalData['trialIndex'],\n","                    'start_time': startTime,\n","                    'end_time': endTime,\n","                    'duration': rawIntervalData['duration'],\n","                    'events': rawIntervalData['trialEvents']\n","                },\n","                'synchronized_data': {}\n","            }\n","\n","            # Process video timing with DEBUG\n","            if hasattr(self.dataLoader, 'videoTimes') and self.dataLoader.videoTimes is not None:\n","                videoFilter = (self.dataLoader.videoTimes \u003e= startTime) \u0026 (self.dataLoader.videoTimes \u003c= endTime)\n","                videoTimes = self.dataLoader.videoTimes[videoFilter]\n","\n","                if len(videoTimes) \u003e 0:\n","                    animationData['synchronized_data']['video_times'] = videoTimes\n","\n","                    # CRITICAL FIX: Get actual frame indices, not relative indices\n","                    frame_indices = np.where(videoFilter)[0]\n","                    animationData['synchronized_data']['video_frame_indices'] = frame_indices\n","\n","                    if self.verbose:\n","                        print(f\"\\nDEBUG: Video timing processing\")\n","                        print(f\"  DataLoader video times: {len(self.dataLoader.videoTimes)} total frames\")\n","                        print(f\"  DataLoader time range: {self.dataLoader.videoTimes[0]:.3f} - {self.dataLoader.videoTimes[-1]:.3f}s\")\n","                        print(f\"  Trial interval: {startTime:.3f} - {endTime:.3f}s\")\n","                        print(f\"  Filtered video times: {len(videoTimes)} frames\")\n","                        print(f\"  Filtered time range: {videoTimes[0]:.3f} - {videoTimes[-1]:.3f}s\")\n","                        print(f\"  Frame indices: {frame_indices[0]} to {frame_indices[-1]} (step: {frame_indices[1]-frame_indices[0] if len(frame_indices)\u003e1 else 'N/A'})\")\n","\n","                        # Check for different camera timestamps\n","                        if hasattr(self.dataLoader, 'standardizedTimestamps'):\n","                            print(f\"  Camera timestamp analysis:\")\n","                            for cam_name, cam_times in self.dataLoader.standardizedTimestamps.items():\n","                                cam_filter = (cam_times \u003e= startTime) \u0026 (cam_times \u003c= endTime)\n","                                cam_in_trial = cam_times[cam_filter]\n","                                cam_indices = np.where(cam_filter)[0]\n","                                print(f\"    {cam_name}: {len(cam_in_trial)} frames, indices {cam_indices[0] if len(cam_indices)\u003e0 else 'N/A'} to {cam_indices[-1] if len(cam_indices)\u003e0 else 'N/A'}\")\n","\n","                                # Check if camera times match our video times\n","                                if cam_name == 'left' and len(cam_in_trial) \u003e 0:\n","                                    time_diff = abs(cam_in_trial[0] - videoTimes[0]) + abs(cam_in_trial[-1] - videoTimes[-1])\n","                                    if time_diff \u003e 0.1:\n","                                        print(f\"    WARNING: {cam_name} camera times don't match video times (diff: {time_diff:.3f}s)\")\n","                                    else:\n","                                        print(f\"    {cam_name} camera times match video times\")\n","\n","            # Add behavioral data\n","            self._addPoseData(animationData, rawIntervalData)\n","            self._addWheelData(animationData, rawIntervalData)\n","            self._addMotionEnergyData(animationData, rawIntervalData)\n","\n","            return animationData\n","\n","        except Exception as e:\n","            if self.verbose:\n","                print(f\"Error preparing animation data: {str(e)}\")\n","            return None\n","\n","    def _addPoseData(self, animationData, rawIntervalData):\n","        \"\"\"Add pose data to animation data structure.\"\"\"\n","        if 'poseData' in rawIntervalData and rawIntervalData['poseData'] is not None:\n","            poseData = rawIntervalData['poseData']\n","            animationData['synchronized_data']['pose'] = {\n","                'times': poseData['times'].values,\n","                'features': {}\n","            }\n","\n","            # Store each pose feature\n","            for feature in poseData.columns:\n","                if feature != 'times':\n","                    featureData = poseData[feature].values\n","                    validMask = ~np.isnan(featureData)\n","\n","                    animationData['synchronized_data']['pose']['features'][feature] = {\n","                        'values': featureData,\n","                        'valid_mask': validMask,\n","                        'valid_times': poseData['times'].values[validMask],\n","                        'valid_values': featureData[validMask]\n","                    }\n","\n","    def _addWheelData(self, animationData, rawIntervalData):\n","        \"\"\"Add wheel data to animation data structure (position-focused).\"\"\"\n","        if 'wheelData' in rawIntervalData and rawIntervalData['wheelData'] is not None:\n","            wheelData = rawIntervalData['wheelData']\n","            animationData['synchronized_data']['wheel'] = {\n","                'times': wheelData['times'],\n","                'position_raw': wheelData.get('position_raw'),\n","            }\n","\n","    def _addMotionEnergyData(self, animationData, rawIntervalData):\n","        \"\"\"Add motion energy data to animation data structure.\"\"\"\n","        if 'motionEnergyData' in rawIntervalData and rawIntervalData['motionEnergyData'] is not None:\n","            motionData = rawIntervalData['motionEnergyData']\n","            animationData['synchronized_data']['motion_energy'] = {\n","                'times': motionData['times'],\n","                'whisker_raw': motionData.get('whiskerMotionEnergy_raw'),\n","                'whisker_smoothed': motionData.get('whiskerMotionEnergy_smoothed')\n","            }\n","\n","\n","# Complete workflow wrapper function\n","def animateIBLSession(eid, mode='test', fps=24, trialIndex=None, verbose=True, baseDir=None):\n","    \"\"\"\n","    Complete workflow to create IBL behavioral animations.\n","\n","    Args:\n","        eid (str): IBL experiment ID\n","        mode (str): 'test' for inline display, 'save' for MP4 output\n","        fps (int): Animation frame rate\n","        trialIndex (int, optional): Specific trial to animate. If None, random trial\n","        verbose (bool): Enable detailed logging\n","        baseDir (str, optional): Base directory for saving (only used in save mode)\n","\n","    Returns:\n","        bool: True if animation succeeded, False otherwise\n","    \"\"\"\n","    try:\n","        if verbose:\n","            print(\"=\"*60)\n","            print(\"IBL ANIMATION WORKFLOW\")\n","            print(\"=\"*60)\n","            print(f\"Experiment ID: {eid}\")\n","            print(f\"Mode: {mode}, FPS: {fps}\")\n","            if trialIndex is not None:\n","                print(f\"Trial: {trialIndex}\")\n","            else:\n","                print(\"Trial: Random\")\n","\n","        # Step 1: Initialize DataLoader\n","        if verbose:\n","            print(\"\\n1. Initializing DataLoader...\")\n","        dataLoader = IBLDataLoader(eid=eid, verbose=verbose)\n","\n","        # Step 2: Load session data\n","        if verbose:\n","            print(\"\\n2. Loading session data...\")\n","        loadSuccess = dataLoader.loadCompleteSession()\n","        if not loadSuccess:\n","            print(\"Session loading failed\")\n","            return False\n","\n","        # Step 3: Create animation renderer\n","        if verbose:\n","            print(\"\\n3. Creating animation renderer...\")\n","        renderer = createAnimationRenderer(dataLoader, mode=mode, fps=fps, verbose=verbose, baseDir=baseDir)\n","\n","        # Step 4: Create animation\n","        if verbose:\n","            print(\"\\n4. Creating animation...\")\n","        if trialIndex is not None:\n","            success = renderer.animateSpecificTrial(trialIndex)\n","        else:\n","            success = renderer.animateRandomInterval()\n","\n","        if verbose:\n","            if success:\n","                print(\"\\nAnimation workflow completed successfully!\")\n","            else:\n","                print(\"\\nAnimation workflow failed\")\n","\n","        return success\n","\n","    except Exception as e:\n","        if verbose:\n","            print(f\"\\nWorkflow error: {str(e)}\")\n","        return False\n","\n","# Convenience functions for easy use\n","def createAnimationRenderer(dataLoader, mode='test', fps=24, verbose=True, baseDir=None, cameras=['left', 'right']):\n","    \"\"\"\n","    Create animation renderer with DataLoader integration.\n","\n","    Args:\n","        dataLoader: IBLDataLoader instance with loaded session data\n","        mode (str): 'test' for inline display, 'save' for MP4 output\n","        fps (int): Animation frame rate\n","        verbose (bool): Enable status messages\n","        baseDir (str, optional): Base directory for saving\n","        cameras (list): List of 1-2 cameras from ['left', 'right', 'body']\n","\n","    Returns:\n","        IBLAnimationRenderer: Ready-to-use animation renderer with DataLoader integration\n","    \"\"\"\n","    return IBLAnimationRenderer(mode=mode, fps=fps, verbose=verbose,\n","                               one=dataLoader.one, eid=dataLoader.eid,\n","                               baseDir=baseDir, dataLoader=dataLoader, cameras=cameras)\n","\n","def quickAnimate(dataLoader, mode='test', fps=24, cameras=['left', 'right']):\n","    \"\"\"\n","    Quick animation of random interval - one-line convenience function.\n","\n","    Args:\n","        dataLoader: IBLDataLoader instance with loaded session data\n","        mode (str): 'test' for inline display, 'save' for MP4 output\n","        fps (int): Animation frame rate\n","        cameras (list): List of 1-2 cameras from ['left', 'right', 'body']\n","\n","    Returns:\n","        bool: True if animation succeeded, False otherwise\n","    \"\"\"\n","    renderer = createAnimationRenderer(dataLoader, mode=mode, fps=fps, cameras=cameras)\n","    return renderer.animateRandomInterval()\n","\n","def animateAllTrials(eid, baseDir, fps=24, maxTrials=None):\n","    \"\"\"\n","    Animate all trials in a session with memory optimization and progress tracking.\n","\n","    Args:\n","        eid (str): Experiment ID\n","        baseDir (str): Base directory for saving\n","        fps (int): Frame rate\n","        maxTrials (int, optional): Limit number of trials (for testing)\n","\n","    Returns:\n","        bool: True if all trials succeeded, False otherwise\n","    \"\"\"\n","    from tqdm import tqdm\n","    import gc\n","    import matplotlib.pyplot as plt\n","\n","    # Load session once with VERBOSE output\n","    print(\"Loading session data...\")\n","\n","    dataLoader = IBLDataLoader(eid=eid, verbose=True)  # Enable verbose for troubleshooting\n","    print(f\"DataLoader initialized for EID: {eid}\")\n","    if not dataLoader.loadCompleteSession():\n","        print(\"Failed to load session\")\n","        return False\n","    print(f\"Session data loaded successfully - {len(dataLoader.trialData)} trials available\")\n","\n","    numTrials = len(dataLoader.trialData)\n","    if maxTrials:\n","        numTrials = min(numTrials, maxTrials)\n","\n","    successCount = 0\n","    failedTrials = []\n","\n","    # Create progress bar\n","    pbar = tqdm(range(numTrials), desc=\"Animating trials\", unit=\"trial\")\n","\n","    for trialIdx in pbar:\n","        pbar.set_description(f\"Processing trial {trialIdx+1}/{numTrials}\")\n","\n","        try:\n","            # Create renderer with reduced chunk size for memory efficiency\n","            renderer = IBLAnimationRenderer(mode='save', baseDir=baseDir, fps=fps,\n","                                           verbose=False, one=dataLoader.one, eid=dataLoader.eid,\n","                                           dataLoader=dataLoader)\n","            renderer.chunkSize = 50  # Reduce memory usage\n","\n","            # Animate trial\n","            success = renderer.animateSpecificTrial(trialIdx)\n","\n","            if success:\n","                successCount += 1\n","                pbar.set_postfix({\"Success\": f\"{successCount}/{trialIdx+1}\", \"Failed\": len(failedTrials)})\n","            else:\n","                failedTrials.append(trialIdx)\n","                pbar.set_postfix({\"Success\": f\"{successCount}/{trialIdx+1}\", \"Failed\": len(failedTrials)})\n","\n","        except Exception as e:\n","            failedTrials.append(trialIdx)\n","            pbar.set_postfix({\"Success\": f\"{successCount}/{trialIdx+1}\", \"Failed\": len(failedTrials)})\n","            # Log error without interrupting progress bar\n","            tqdm.write(f\"Error on trial {trialIdx}: {e}\")\n","\n","        finally:\n","            # Critical cleanup to prevent memory issues\n","            plt.close('all')\n","            if 'renderer' in locals():\n","                # Clear both camera caches\n","                for cache in renderer.videoFrameCaches.values():\n","                    cache.clear()\n","                del renderer\n","            gc.collect()\n","\n","    pbar.close()\n","\n","    # Final summary\n","    print(f\"\\nBatch processing completed:\")\n","    print(f\"  Successful: {successCount}/{numTrials} trials\")\n","    print(f\"  Failed: {len(failedTrials)} trials\")\n","    if failedTrials:\n","        print(f\"  Failed trial indices: {failedTrials}\")\n","\n","    return successCount == numTrials\n","\n","# Quick batch processing functions\n","def quickBatchAnimate(eid, baseDir, maxTrials=None, fps=24):\n","    \"\"\"\n","    Quick batch animation for testing (limits to first few trials).\n","\n","    Args:\n","        eid (str): Experiment ID\n","        baseDir (str): Base directory for saving\n","        maxTrials (int): Maximum number of trials to process\n","        fps (int): Frame rate\n","    \"\"\"\n","    print(f\"Quick batch test: processing first {maxTrials} trials\")\n","    return animateAllTrials(eid, baseDir, fps=fps, maxTrials=maxTrials)"]},{"cell_type":"markdown","metadata":{"id":"PslK1jBL_a58"},"source":["# Running through eids\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1753731267896,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"cDANUI8KVgPY"},"outputs":[],"source":["eid = '88d24c31-52e4-49cc-9f32-6adbeb9eba87'\n","pca_path = '/content/drive/MyDrive/S25/Langone/Breathing/Figures/hoferlab/SWC_043/88d24c31-52e4-49cc-9f32-6adbeb9eba87/88d24c31-52e4-49cc-9f32-6adbeb9eba87_pca1_full.csv'"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1753731316525,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"vXcxBjvAXX0y","outputId":"8a4fe344-1be6-4af7-a5ab-c60b7ae0654d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing IBL DataLoader for experiment: 88d24c31-52e4-49cc-9f32-6adbeb9eba87\n"]}],"source":["dataLoader = IBLDataLoader(\n","    eid=eid,\n","    verbose=True,\n","    nosePCAPath=pca_path\n",")"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":58049,"status":"ok","timestamp":1753731434567,"user":{"displayName":"Andrew Liao","userId":"01433793926959815213"},"user_tz":240},"id":"Ofm9KzsTiPvv","outputId":"b3c18088-517a-4b2d-ed84-a9cda922353d"},"outputs":[{"name":"stdout","output_type":"stream","text":["============================================================\n","STARTING COMPLETE SESSION LOADING\n","============================================================\n","\n","Loading session data...\n","Loading session data...\n","\u001b[36m2025-07-28 19:36:16 INFO     one.py:1475 Loading trials data\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:ibllib:Loading trials data\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m2025-07-28 19:36:22 INFO     one.py:1475 Loading wheel data\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:ibllib:Loading wheel data\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m2025-07-28 19:36:27 INFO     one.py:1475 Loading pose data\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:ibllib:Loading pose data\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m2025-07-28 19:36:39 INFO     one.py:1475 Loading motion_energy data\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:ibllib:Loading motion_energy data\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m2025-07-28 19:36:43 INFO     one.py:1475 Loading pupil data\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["INFO:ibllib:Loading pupil data\n"]},{"name":"stdout","output_type":"stream","text":["✓ Session data loaded successfully\n","✓ Completed: Loading session data\n","\n","Extracting session info...\n","Extracting session information...\n","  Raw session path: /root/Downloads/ONE/openalyx.internationalbrainlab.org/hoferlab/Subjects/SWC_043/2020-09-19/001\n","✓ Session info extracted:\n","  experimentId: 88d24c31-52e4-49cc-9f32-6adbeb9eba87\n","  subject: SWC_043\n","  date: 2020-09-19\n","  sessionNumber: 001\n","  lab: hoferlab\n","  taskProtocol: _iblrig_tasks_ephysChoiceWorld6.4.2\n","  numberOfTrials: 547\n","  sessionPath: /root/Downloads/ONE/openalyx.internationalbrainlab.org/hoferlab/Subjects/SWC_043/2020-09-19/001\n","  dataRepository: Unknown\n","✓ Completed: Extracting session info\n","\n","Validating trial data...\n","Validating and extracting trial data...\n","✓ Trial data loaded: 547 trials\n","  Available features: 15\n","  ✓ All required trial features present\n","  Trial duration stats:\n","    Mean: 4.91s\n","    Min: 2.11s\n","    Max: 63.17s\n","✓ Completed: Validating trial data\n","\n","Validating pose data...\n","Validating and extracting pose data...\n","✓ Loaded and injected nose_pc from CSV: /content/drive/MyDrive/S25/Langone/Breathing/Figures/hoferlab/SWC_043/88d24c31-52e4-49cc-9f32-6adbeb9eba87/88d24c31-52e4-49cc-9f32-6adbeb9eba87_pca1_full.csv\n","✓ Completed: Validating pose data\n","\n","Extracting behavioral data...\n","Extracting additional behavioral data...\n","✓ Wheel data: 4418069 timepoints\n","✓ Pose data loaded for cameras: ['leftCamera', 'rightCamera', 'bodyCamera']\n","  Feature analysis across 3 cameras:\n","    Common features (1): ['times']\n","    leftCamera unique features (33): ['nose_tip_likelihood', 'nose_tip_x', 'nose_tip_y', 'paw_l_likelihood', 'paw_l_x', 'paw_l_y', 'paw_r_likelihood', 'paw_r_x', 'paw_r_y', 'pupil_bottom_r_likelihood', 'pupil_bottom_r_x', 'pupil_bottom_r_y', 'pupil_left_r_likelihood', 'pupil_left_r_x', 'pupil_left_r_y', 'pupil_right_r_likelihood', 'pupil_right_r_x', 'pupil_right_r_y', 'pupil_top_r_likelihood', 'pupil_top_r_x', 'pupil_top_r_y', 'tongue_end_l_likelihood', 'tongue_end_l_x', 'tongue_end_l_y', 'tongue_end_r_likelihood', 'tongue_end_r_x', 'tongue_end_r_y', 'tube_bottom_likelihood', 'tube_bottom_x', 'tube_bottom_y', 'tube_top_likelihood', 'tube_top_x', 'tube_top_y']\n","    rightCamera unique features (33): ['nose_tip_likelihood', 'nose_tip_x', 'nose_tip_y', 'paw_l_likelihood', 'paw_l_x', 'paw_l_y', 'paw_r_likelihood', 'paw_r_x', 'paw_r_y', 'pupil_bottom_r_likelihood', 'pupil_bottom_r_x', 'pupil_bottom_r_y', 'pupil_left_r_likelihood', 'pupil_left_r_x', 'pupil_left_r_y', 'pupil_right_r_likelihood', 'pupil_right_r_x', 'pupil_right_r_y', 'pupil_top_r_likelihood', 'pupil_top_r_x', 'pupil_top_r_y', 'tongue_end_l_likelihood', 'tongue_end_l_x', 'tongue_end_l_y', 'tongue_end_r_likelihood', 'tongue_end_r_x', 'tongue_end_r_y', 'tube_bottom_likelihood', 'tube_bottom_x', 'tube_bottom_y', 'tube_top_likelihood', 'tube_top_x', 'tube_top_y']\n","    bodyCamera unique features (3): ['tail_start_likelihood', 'tail_start_x', 'tail_start_y']\n","    Pupil tracking available in: ['leftCamera', 'rightCamera']\n","      leftCamera: ['pupil_top_r_x', 'pupil_right_r_x', 'pupil_left_r_y', 'pupil_left_r_x', 'pupil_bottom_r_x', 'pupil_top_r_likelihood', 'pupil_top_r_y', 'pupil_bottom_r_y', 'pupil_right_r_y', 'pupil_right_r_likelihood', 'pupil_left_r_likelihood', 'pupil_bottom_r_likelihood']\n","      rightCamera: ['pupil_top_r_x', 'pupil_right_r_x', 'pupil_left_r_y', 'pupil_left_r_x', 'pupil_bottom_r_x', 'pupil_top_r_likelihood', 'pupil_top_r_y', 'pupil_bottom_r_y', 'pupil_right_r_y', 'pupil_right_r_likelihood', 'pupil_left_r_likelihood', 'pupil_bottom_r_likelihood']\n","✓ Re-injected nose_pc from CSV: /content/drive/MyDrive/S25/Langone/Breathing/Figures/hoferlab/SWC_043/88d24c31-52e4-49cc-9f32-6adbeb9eba87/88d24c31-52e4-49cc-9f32-6adbeb9eba87_pca1_full.csv\n","✓ Motion energy data loaded for cameras: ['leftCamera', 'rightCamera', 'bodyCamera']\n","    leftCamera: ['whiskerMotionEnergy']\n","    rightCamera: ['whiskerMotionEnergy']\n","    bodyCamera: ['whiskerMotionEnergy']\n","✓ Completed: Extracting behavioral data\n","\n","Loading video timestamps...\n","Loading video timestamps...\n","  left camera frames: 260646\n","  right camera frames: 654111\n","  body camera frames: 130553\n","  left: 260646 frames over 4360.85s → 60 fps\n","  right: 654111 frames over 4360.87s → 150 fps\n","  body: 130553 frames over 4360.85s → 30 fps\n","✓ Video timestamps loaded; using left camera as master timeline\n","✓ Completed: Loading video timestamps\n","\n","============================================================\n","SESSION LOADING COMPLETED SUCCESSFULLY\n","============================================================\n"]},{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["dataLoader.loadCompleteSession()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Ldf8QXMyi_6h"},"outputs":[{"name":"stdout","output_type":"stream","text":["IBL Animation Renderer initialized with DataLoader for subject SWC_043\n","Animating trial 5...\n","  Pose data in interval: 1000 timepoints\n","    High quality features (\u003e80%): 14\n","    Medium quality features (20-80%): 0\n","    Low quality features (\u003c20%): 4\n","    Low quality features will rely on interpolation: ['tongue_end_l_x', 'tongue_end_l_y', 'tongue_end_r_x']...\n","✓ Wheel data extracted: 16720 timepoints\n","  Time range: 73.760 - 90.479s\n","  Position range: 23.487770 - 39.723949\n","  Valid positions: 16720\n","Motion energy data type: \u003cclass 'pandas.core.frame.DataFrame'\u003e\n","Motion energy DataFrame columns: ['times', 'whiskerMotionEnergy']\n","Using column 'whiskerMotionEnergy' for whisker motion energy\n","✓ Motion energy extracted: 1000 timepoints\n","  Time range: 73.762 - 90.476s\n","  Data range: 0.757 - 18.343\n","\n","DEBUG: Video timing processing\n","  DataLoader video times: 260646 total frames\n","  DataLoader time range: 53.016 - 4413.863s\n","  Trial interval: 73.759 - 90.479s\n","  Filtered video times: 1000 frames\n","  Filtered time range: 73.762 - 90.476s\n","  Frame indices: 1240 to 2239 (step: 1)\n","Rendering 16.7s trial for subject SWC_043 (1000 frames)\n","\n","DEBUG: TIME SYNCHRONIZATION ANALYSIS\n","  Trial interval: 73.759 - 90.479s\n","  Video times range: 73.762 - 90.476s\n","  Video duration: 16.714s\n","  Total video frames: 1000\n","  Video frame rate: 59.83 fps\n","  Video frame indices: 1240 to 2239 (range: 1000)\n","  Uniform frame indices (step: 1)\n","  Animation will use video times as master clock\n","Video URLs loaded for selected cameras: ['left', 'right']\n","DEBUGGING EVENT EXTRACTION:\n","Trial interval: 73.759 - 90.479s\n","Available trial event keys: ['stimOff_times', 'goCueTrigger_times', 'choice', 'contrastRight', 'contrastLeft', 'feedback_times', 'feedbackType', 'rewardVolume', 'response_times', 'goCue_times', 'stimOn_times', 'probabilityLeft', 'firstMovement_times', 'intervals_0', 'intervals_1']\n","  Extracting stimOn:\n","    Checking direct key: stimOn_times\n","    Found data: 88.64586786008864 (type: \u003cclass 'float'\u003e)\n","    Valid time from scalar: 88.64586786008864\n","stimOn:\n","  Raw event times: [88.64586786008864]\n","  Valid event times (within interval): [88.64586786008864]\n","  Added 1 event markers\n","  Extracting stimOff:\n","    Checking direct key: stimOff_times\n","    Found data: 89.97916785008998 (type: \u003cclass 'float'\u003e)\n","    Valid time from scalar: 89.97916785008998\n","stimOff:\n","  Raw event times: [89.97916785008998]\n","  Valid event times (within interval): [89.97916785008998]\n","  Added 1 event markers\n","  Extracting firstMovement:\n","    Checking direct key: firstMovement_times\n","    Found data: 88.77693294 (type: \u003cclass 'float'\u003e)\n","    Valid time from scalar: 88.77693294\n","firstMovement:\n","  Raw event times: [88.77693294]\n","  Valid event times (within interval): [88.77693294]\n","  Added 1 event markers\n","  Extracting response:\n","    Checking direct key: response_times\n","    Found data: 88.93407643352953 (type: \u003cclass 'float'\u003e)\n","    Valid time from scalar: 88.93407643352953\n","response:\n","  Raw event times: [88.93407643352953]\n","  Valid event times (within interval): [88.93407643352953]\n","  Added 1 event markers\n","  Extracting feedback:\n","    Checking direct key: feedback_times\n","    Found data: 88.93417236008894 (type: \u003cclass 'float'\u003e)\n","    Valid time from scalar: 88.93417236008894\n","feedback:\n","  Raw event times: [88.93417236008894]\n","  Valid event times (within interval): [88.93417236008894]\n","  Added 1 event markers\n","Added legend for 5 event types\n","Frame 0: Time=73.762s, VideoFrameIdx=1240\n","   Trial progress: 0.0% (73.762s / 16.720s)\n","CORRECTED: Camera left frame 0: AnimTime=73.762s\n","   Best camera frame: 1240, actual time: 73.762s\n","   Timing error: 0.0ms\n","   Excellent timing alignment\n","\n","DEBUG: Corrected video loading for left\n","  Animation frames: 0 to 99\n","  Animation times: 73.762s to 75.418s\n","  left frame indices: 1240 to 1339\n","  Timing errors: avg=0.0ms, max=0.0ms\n","Loaded left: 100 frames with corrected timing\n","CORRECTED: Camera right frame 0: AnimTime=73.762s\n","   Best camera frame: 3111, actual time: 73.763s\n","   Timing error: 1.1ms\n","   Excellent timing alignment\n","\n","DEBUG: Corrected video loading for right\n","  Animation frames: 0 to 99\n","  Animation times: 73.762s to 75.418s\n","  right frame indices: 3111 to 3359\n","  Timing errors: avg=1.7ms, max=3.3ms\n","Loaded right: 100 frames with corrected timing\n","Frame 0: Time=73.762s, VideoFrameIdx=1240\n","   Trial progress: 0.0% (73.762s / 16.720s)\n","CORRECTED: Camera left frame 0: AnimTime=73.762s\n","   Best camera frame: 1240, actual time: 73.762s\n","   Timing error: 0.0ms\n","   Excellent timing alignment\n","CORRECTED: Camera right frame 0: AnimTime=73.762s\n","   Best camera frame: 3111, actual time: 73.763s\n","   Timing error: 1.1ms\n","   Excellent timing alignment\n","Displaying animation...\n","Frame 0: Time=73.762s, VideoFrameIdx=1240\n","   Trial progress: 0.0% (73.762s / 16.720s)\n","CORRECTED: Camera left frame 0: AnimTime=73.762s\n","   Best camera frame: 1240, actual time: 73.762s\n","   Timing error: 0.0ms\n","   Excellent timing alignment\n","CORRECTED: Camera right frame 0: AnimTime=73.762s\n","   Best camera frame: 3111, actual time: 73.763s\n","   Timing error: 1.1ms\n","   Excellent timing alignment\n","Frame 0: Time=73.762s, VideoFrameIdx=1240\n","   Trial progress: 0.0% (73.762s / 16.720s)\n","CORRECTED: Camera left frame 0: AnimTime=73.762s\n","   Best camera frame: 1240, actual time: 73.762s\n","   Timing error: 0.0ms\n","   Excellent timing alignment\n","CORRECTED: Camera right frame 0: AnimTime=73.762s\n","   Best camera frame: 3111, actual time: 73.763s\n","   Timing error: 1.1ms\n","   Excellent timing alignment\n","Frame 1: Time=73.779s, VideoFrameIdx=1241\n","   Trial progress: 0.1% (73.779s / 16.720s)\n","CORRECTED: Camera left frame 1: AnimTime=73.779s\n","   Best camera frame: 1241, actual time: 73.779s\n","   Timing error: 0.0ms\n","   Excellent timing alignment\n","CORRECTED: Camera right frame 1: AnimTime=73.779s\n","   Best camera frame: 3113, actual time: 73.776s\n","   Timing error: 2.3ms\n","   Excellent timing alignment\n","Frame 2: Time=73.795s, VideoFrameIdx=1242\n","   Trial progress: 0.2% (73.795s / 16.720s)\n","CORRECTED: Camera left frame 2: AnimTime=73.795s\n","   Best camera frame: 1242, actual time: 73.795s\n","   Timing error: 0.0ms\n","   Excellent timing alignment\n","CORRECTED: Camera right frame 2: AnimTime=73.795s\n","   Best camera frame: 3116, actual time: 73.796s\n","   Timing error: 1.0ms\n","   Excellent timing alignment\n","Frame 3: Time=73.812s, VideoFrameIdx=1243\n","   Trial progress: 0.3% (73.812s / 16.720s)\n","Frame 4: Time=73.829s, VideoFrameIdx=1244\n","   Trial progress: 0.4% (73.829s / 16.720s)\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:matplotlib.animation:Animation size has reached 210025077 bytes, exceeding the limit of 209715200.0. If you're sure you want a larger animation embedded, set the animation.embed_limit rc parameter to a larger value (in MB). This and further frames will be dropped.\n"]},{"name":"stdout","output_type":"stream","text":["Buffered data was truncated after reaching the output size limit."]}],"source":["renderer = createAnimationRenderer(\n","    dataLoader,\n","    mode='test',     # 'test' for inline, 'save' to write MP4\n","    fps=24,\n","    verbose=True,\n","    baseDir='./animations',  # only used if mode='save'\n","    cameras=['left','right']\n",")\n","\n","# 7a. Animate a specific trial (e.g. trial 5)\n","success = renderer.animateSpecificTrial(trialIndex=5)\n","print(\"Animation success:\", success)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q_kjAX8XkMzZ"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNWepf85lqp54ctEduhg2UK","collapsed_sections":["lvBc4yFubJyQ","1nkBJ3NDzg1h"],"mount_file_id":"1H0iu7H4L1l8T97QhtW2VCfeHcpeVki6K","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}